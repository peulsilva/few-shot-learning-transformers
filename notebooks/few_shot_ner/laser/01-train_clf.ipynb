{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.nn.functional import cross_entropy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from torcheval.metrics.functional import multiclass_f1_score, multiclass_confusion_matrix\n",
    "from copy import deepcopy, copy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from huggingface_hub import notebook_login\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import os \n",
    "while 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import re\n",
    "from typing import List, Dict\n",
    "    \n",
    "from src.preprocessing.laser.laser_processor import LaserProcessor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90863fafdbba469e9ec0e10029092a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘logs’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir logs\n",
    "model_name = \"LASER-CLF\"\n",
    "dataset_name = \"FUNSD\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "logging.basicConfig(filename=f'logs/{model_name}_{dataset_name}.log', encoding='utf-8', level= logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training binary classifier modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\", \n",
    "    num_labels=2\n",
    "\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"nielsr/funsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/149 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [00:25<00:00,  5.93it/s]\n"
     ]
    }
   ],
   "source": [
    "laser_data = LaserProcessor(\n",
    "    train_dataset,\n",
    "    tokenizer=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_chars = set([\"[B]\", \"[E]\", \"[T]\", \"QUESTION\", \"ANSWER\", \"NONE\", \"HEADER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c32b4d604346acb682eb125d9da6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acb06f14a41449f84f0a66219c7413a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50261. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      " 14%|█▍        | 1/7 [00:31<03:06, 31.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few-shot-learning/laser/01-train_clf.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few-shot-learning/laser/01-train_clf.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m tokenizer(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few-shot-learning/laser/01-train_clf.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(in_stack),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few-shot-learning/laser/01-train_clf.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     truncation\u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few-shot-learning/laser/01-train_clf.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m     max_length\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few-shot-learning/laser/01-train_clf.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few-shot-learning/laser/01-train_clf.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few-shot-learning/laser/01-train_clf.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39minput\u001b[39m[k] \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few-shot-learning/laser/01-train_clf.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mif\u001b[39;00m next_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few-shot-learning/laser/01-train_clf.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m     labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "device = \"cuda\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\", \n",
    "    num_labels=2,\n",
    ").to(device)\n",
    "\n",
    "tokenizer.add_special_tokens({\n",
    "    'pad_token': '[PAD]',\n",
    "})\n",
    "\n",
    "tokenizer.add_tokens([\n",
    "    \"[B]\",\n",
    "    \"[E]\",\n",
    "    \"[T]\"\n",
    "])\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "# for param in model.distilbert.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 1e-5\n",
    ")\n",
    "\n",
    "# 0 -> not in src\n",
    "# 1 -> in src\n",
    "\n",
    "n_shots_train = 7\n",
    "n_shots_val = 10\n",
    "n_epochs = 2\n",
    "best_f1 = 0\n",
    "best_model = None\n",
    "for epoch in range(n_epochs):\n",
    "    for i in tqdm(range(n_shots_train)):\n",
    "        X, y = laser_data[i]\n",
    "        out_stack = deque(y.split(' '),)\n",
    "        in_stack = deque(X.split(' '), maxlen=16)\n",
    "        y_true_train = []\n",
    "        y_pred_train = []\n",
    "\n",
    "        next_token = None\n",
    "        while len(out_stack) >0:\n",
    "            input = tokenizer(\n",
    "                ' '.join(in_stack),\n",
    "                truncation= True,\n",
    "                padding= \"max_length\",\n",
    "                return_tensors= \"pt\",\n",
    "                max_length=32,\n",
    "            )\n",
    "\n",
    "            for k, v in input.items():\n",
    "                input[k] = v.to(device)\n",
    "\n",
    "            if next_token is None:\n",
    "                labels = torch.tensor(0).to(device)\n",
    "            elif next_token in special_chars:\n",
    "                labels = torch.tensor(0).to(device)\n",
    "            \n",
    "            else:\n",
    "                labels = torch.tensor(1).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            model_output = model(**input).logits.squeeze()\n",
    "            loss = loss_fn(model_output, labels)\n",
    "\n",
    "            y_pred_train.append(model_output.argmax().item())\n",
    "            y_true_train.append(labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            next_token = out_stack.popleft()\n",
    "            in_stack.append(next_token)\n",
    "\n",
    "        # validation \n",
    "        with torch.no_grad():\n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            for i in range(n_shots_train, n_shots_train + n_shots_val):\n",
    "                X, y = laser_data[i]\n",
    "                out_stack = deque(y.split(' '))\n",
    "                in_stack = deque(X.split(' '), maxlen=16)\n",
    "\n",
    "                next_token = None\n",
    "                while len(out_stack) >0:\n",
    "                    input = tokenizer(\n",
    "                        ' '.join(in_stack),\n",
    "                        truncation= True,\n",
    "                        padding= \"max_length\",\n",
    "                        return_tensors= \"pt\",\n",
    "                        max_length=32,\n",
    "                    )\n",
    "\n",
    "                    for k, v in input.items():\n",
    "                        input[k] = v.to(device)\n",
    "\n",
    "                    if next_token is None:\n",
    "                        labels = torch.tensor(0).to(device)\n",
    "                    elif next_token in special_chars:\n",
    "                        labels = torch.tensor(0).to(device)\n",
    "                    \n",
    "                    else:\n",
    "                        labels= torch.tensor(1).to(device)\n",
    "                    \n",
    "                    model_output = model(**input).logits.squeeze()\n",
    "                    y_pred.append(model_output.argmax().item())\n",
    "                    y_true.append(labels)\n",
    "\n",
    "                    next_token = out_stack.popleft()\n",
    "                    in_stack.append(next_token) \n",
    "\n",
    "            f1 = multiclass_f1_score(torch.Tensor(y_pred), torch.Tensor(y_true), num_classes=2)\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_model = deepcopy(model)\n",
    "\n",
    "            logging.info(f\"Validation F1 - score: {f1}\")\n",
    "            logging.info(\n",
    "                multiclass_confusion_matrix(\n",
    "                    torch.Tensor(y_pred,).to(torch.int64), \n",
    "                    torch.Tensor(y_true).to(torch.int64), \n",
    "                    num_classes=2\n",
    "                )\n",
    "            )\n",
    "best_model.push_to_hub(\"peulsilva/LASER-CLF-GPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cc41eeef0c4cacadd7bd74ce35cdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/566 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a721f708765a4c5b8835d04853d6fe33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"peulsilva/LASER-CLF\", \n",
    "    num_labels=2,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 30525. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "  0%|          | 0/142 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [01:18<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# validation \n",
    "n_shots_train = 7\n",
    "n_shots_val = 149 - n_shots_train\n",
    "tokenizer.add_special_tokens({\n",
    "    'pad_token': '[PAD]',\n",
    "})\n",
    "\n",
    "tokenizer.add_tokens([\n",
    "    \"[B]\",\n",
    "    \"[E]\",\n",
    "    \"[T]\"\n",
    "])\n",
    "\n",
    "trained_model.resize_token_embeddings(len(tokenizer))\n",
    "with torch.no_grad():\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for i in tqdm(range(n_shots_train, n_shots_train + n_shots_val)):\n",
    "        X, y = laser_data[i]\n",
    "        out_stack = deque(y.split(' '))\n",
    "        in_stack = deque(X.split(' '), maxlen=3)\n",
    "\n",
    "        next_token = None\n",
    "        while len(out_stack) >0:\n",
    "            input = tokenizer(\n",
    "                ' '.join(in_stack),\n",
    "                truncation= True,\n",
    "                padding= \"max_length\",\n",
    "                return_tensors= \"pt\",\n",
    "                max_length=3,\n",
    "            )\n",
    "\n",
    "            for k, v in input.items():\n",
    "                input[k] = v.to(device)\n",
    "\n",
    "            if next_token is None:\n",
    "                labels = torch.tensor(0).to(device)\n",
    "            elif next_token in special_chars:\n",
    "                labels = torch.tensor(0).to(device)\n",
    "            \n",
    "            else:\n",
    "                labels= torch.tensor(1).to(device)\n",
    "            \n",
    "            model_output = trained_model(**input).logits.squeeze()\n",
    "            y_pred.append(model_output.argmax().item())\n",
    "            y_true.append(labels)\n",
    "\n",
    "            next_token = out_stack.popleft()\n",
    "            in_stack.append(next_token) \n",
    "\n",
    "    f1 = multiclass_f1_score(torch.Tensor(y_pred), torch.Tensor(y_true), num_classes=2)\n",
    "    logging.info(f\"Validation F1 - score: {f1}\")\n",
    "    logging.info(\n",
    "        multiclass_confusion_matrix(\n",
    "            torch.Tensor(y_pred,).to(torch.int64), \n",
    "            torch.Tensor(y_true).to(torch.int64), \n",
    "            num_classes=2\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = multiclass_f1_score(torch.Tensor(y_pred), torch.Tensor(y_true), num_classes=2)\n",
    "conf = multiclass_confusion_matrix(\n",
    "            torch.Tensor(y_pred,).to(torch.int64), \n",
    "            torch.Tensor(y_true).to(torch.int64), \n",
    "            num_classes=2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7519)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
