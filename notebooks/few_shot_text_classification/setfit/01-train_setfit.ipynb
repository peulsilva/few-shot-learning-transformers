{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.nn.functional import cross_entropy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from torcheval.metrics.functional import multiclass_f1_score, multiclass_confusion_matrix, binary_f1_score\n",
    "from copy import deepcopy, copy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from huggingface_hub import notebook_login\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict, deque\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "\n",
    "import os \n",
    "while 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import re\n",
    "from typing import List, Dict\n",
    "    \n",
    "from src.preprocessing.sequence_classification.dataset import get_n_shots_per_class\n",
    "from src.preprocessing.sequence_classification.set_fit_dataset import SetFitDataset\n",
    "from src.model.sequence_classification.trainer import SequenceClassificationTrainer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58cbf80d1fce41a2b6cd2fca89ec1da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘logs’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir logs\n",
    "model_name = \"SetFit\"\n",
    "dataset_name = \"AG_news\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "# logging.basicConfig(filename=f'logs/{model_name}_{dataset_name}.log', encoding='utf-8', level= logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SetFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.98/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m SentenceTransformer(\u001b[39m\"\u001b[39;49m\u001b[39mwhaleloops/phrase-bert\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:95\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[1;32m     87\u001b[0m         snapshot_download(model_name_or_path,\n\u001b[1;32m     88\u001b[0m                             cache_dir\u001b[39m=\u001b[39mcache_folder,\n\u001b[1;32m     89\u001b[0m                             library_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msentence-transformers\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     90\u001b[0m                             library_version\u001b[39m=\u001b[39m__version__,\n\u001b[1;32m     91\u001b[0m                             ignore_files\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mflax_model.msgpack\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrust_model.ot\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtf_model.h5\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     92\u001b[0m                             use_auth_token\u001b[39m=\u001b[39muse_auth_token)\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m'\u001b[39m\u001b[39mmodules.json\u001b[39m\u001b[39m'\u001b[39m)):    \u001b[39m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     modules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_sbert_model(model_path)\n\u001b[1;32m     96\u001b[0m \u001b[39melse\u001b[39;00m:   \u001b[39m#Load with AutoModel\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     modules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_auto_model(model_path)\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:840\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[39mfor\u001b[39;00m module_config \u001b[39min\u001b[39;00m modules_config:\n\u001b[1;32m    839\u001b[0m     module_class \u001b[39m=\u001b[39m import_from_string(module_config[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 840\u001b[0m     module \u001b[39m=\u001b[39m module_class\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(model_path, module_config[\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n\u001b[1;32m    841\u001b[0m     modules[module_config[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m module\n\u001b[1;32m    843\u001b[0m \u001b[39mreturn\u001b[39;00m modules\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/sentence_transformers/models/Transformer.py:137\u001b[0m, in \u001b[0;36mTransformer.load\u001b[0;34m(input_path)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(sbert_config_path) \u001b[39mas\u001b[39;00m fIn:\n\u001b[1;32m    136\u001b[0m     config \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(fIn)\n\u001b[0;32m--> 137\u001b[0m \u001b[39mreturn\u001b[39;00m Transformer(model_name_or_path\u001b[39m=\u001b[39;49minput_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig)\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/sentence_transformers/models/Transformer.py:29\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_lower_case \u001b[39m=\u001b[39m do_lower_case\n\u001b[1;32m     28\u001b[0m config \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_args, cache_dir\u001b[39m=\u001b[39mcache_dir)\n\u001b[0;32m---> 29\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_model(model_name_or_path, config, cache_dir)\n\u001b[1;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(tokenizer_name_or_path \u001b[39mif\u001b[39;00m tokenizer_name_or_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m model_name_or_path, cache_dir\u001b[39m=\u001b[39mcache_dir, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtokenizer_args)\n\u001b[1;32m     33\u001b[0m \u001b[39m#No max_seq_length set. Try to infer from model\u001b[39;00m\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/sentence_transformers/models/Transformer.py:49\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[0;34m(self, model_name_or_path, config, cache_dir)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_t5_model(model_name_or_path, config, cache_dir)\n\u001b[1;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_model \u001b[39m=\u001b[39m AutoModel\u001b[39m.\u001b[39;49mfrom_pretrained(model_name_or_path, config\u001b[39m=\u001b[39;49mconfig, cache_dir\u001b[39m=\u001b[39;49mcache_dir)\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    567\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    568\u001b[0m     )\n\u001b[1;32m    569\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/transformers/modeling_utils.py:3170\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3167\u001b[0m \u001b[39mif\u001b[39;00m from_pt:\n\u001b[1;32m   3168\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sharded \u001b[39mand\u001b[39;00m state_dict \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3169\u001b[0m         \u001b[39m# Time to load the checkpoint\u001b[39;00m\n\u001b[0;32m-> 3170\u001b[0m         state_dict \u001b[39m=\u001b[39m load_state_dict(resolved_archive_file)\n\u001b[1;32m   3172\u001b[0m     \u001b[39m# set dtype to instantiate the model under:\u001b[39;00m\n\u001b[1;32m   3173\u001b[0m     \u001b[39m# 1. If torch_dtype is not None, we use that dtype\u001b[39;00m\n\u001b[1;32m   3174\u001b[0m     \u001b[39m# 2. If torch_dtype is \"auto\", we auto-detect dtype from the loaded state_dict, by checking its first\u001b[39;00m\n\u001b[1;32m   3175\u001b[0m     \u001b[39m#    weights entry that is of a floating type - we assume all floating dtype weights are of the same dtype\u001b[39;00m\n\u001b[1;32m   3176\u001b[0m     \u001b[39m# we also may have config.torch_dtype available, but we won't rely on it till v5\u001b[39;00m\n\u001b[1;32m   3177\u001b[0m     dtype_orig \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/transformers/modeling_utils.py:484\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m         map_location \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 484\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(checkpoint_file, map_location\u001b[39m=\u001b[39;49mmap_location)\n\u001b[1;32m    485\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    486\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    810\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1174\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1144\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/torch/serialization.py:1112\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_tensor\u001b[39m(dtype, numel, key, location):\n\u001b[1;32m   1110\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1112\u001b[0m     storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39;49mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39;49mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m     \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[1;32m   1116\u001b[0m         wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1117\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m         _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"whaleloops/phrase-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch.hub import _get_torch_home\n",
    "\n",
    "    torch_cache_home = _get_torch_home()\n",
    "except ImportError:\n",
    "    torch_cache_home = os.path.expanduser(os.getenv('TORCH_HOME', os.path.join(os.getenv('XDG_CACHE_HOME', '~/.cache'), 'torch')))\n",
    "\n",
    "cache_folder = os.path.join(torch_cache_home, 'sentence_transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/eleves-a/2022/pedro.silva/.cache/torch/sentence_transformers'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.98/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading AGnews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0093d1009d4542b0e3b3e91dc5f1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324acf479e024e62af658212c6faf05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02e7648d4934763a84ed8c00f697f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0954137a0e6544f1a37e990ef6a3c90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ag_news_dataset = load_dataset(\"ag_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(ag_news_dataset['train']\\\n",
    "    .features['label']\\\n",
    "    .names)\n",
    "\n",
    "classes_names = ag_news_dataset['train']\\\n",
    "    .features['label']\\\n",
    "    .names\n",
    "\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size = len(ag_news_dataset['train'])\n",
    "data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = ag_news_dataset['train']['text'][0:data_size*3//5]\n",
    "train_labels = ag_news_dataset['train']['label'][0:data_size*3//5]\n",
    "\n",
    "val_text = ag_news_dataset['train']['text'][data_size*3//5:]\n",
    "val_labels = ag_news_dataset['train']['label'][data_size*3//5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots =2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_n_shots_per_class(\n",
    "    train_text,\n",
    "    train_labels,\n",
    "    n_shots= n_shots,\n",
    "    num_classes= num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = get_n_shots_per_class(\n",
    "    val_text, \n",
    "    val_labels,\n",
    "    n_shots = 10,\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_fit_data_train = SetFitDataset(\n",
    "    X_train,\n",
    "    y_train, \n",
    "    input_example_format= True\n",
    "    # R = 5\n",
    ")\n",
    "\n",
    "set_fit_data_val = SetFitDataset(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    # R = 5,\n",
    "    input_example_format= False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    set_fit_data_train.data,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    set_fit_data_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running validation after 0 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 128.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.48985961079597473\n",
      "tensor([[296, 304],\n",
      "        [ 23, 157]], device='cuda:0')\n",
      "Running validation after 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 125.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.4906250238418579\n",
      "tensor([[297, 303],\n",
      "        [ 23, 157]], device='cuda:0')\n",
      "Running validation after 2 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 124.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.4921630024909973\n",
      "tensor([[299, 301],\n",
      "        [ 23, 157]], device='cuda:0')\n",
      "Running validation after 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 123.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.4864865243434906\n",
      "tensor([[304, 296],\n",
      "        [ 27, 153]], device='cuda:0')\n",
      "Running validation after 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 123.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.49275365471839905\n",
      "tensor([[312, 288],\n",
      "        [ 27, 153]], device='cuda:0')\n",
      "Running validation after 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 123.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.4886731207370758\n",
      "tensor([[313, 287],\n",
      "        [ 29, 151]], device='cuda:0')\n",
      "Running validation after 6 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 122.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.4910568594932556\n",
      "tensor([[316, 284],\n",
      "        [ 29, 151]], device='cuda:0')\n",
      "Running validation after 7 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 122.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.49508199095726013\n",
      "tensor([[321, 279],\n",
      "        [ 29, 151]], device='cuda:0')\n",
      "Running validation after 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 122.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.4958677887916565\n",
      "tensor([[325, 275],\n",
      "        [ 30, 150]], device='cuda:0')\n",
      "Running validation after 9 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 122.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.5016722679138184\n",
      "tensor([[332, 268],\n",
      "        [ 30, 150]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Cloning https://huggingface.co/peulsilva/phrase-bert-setfit-2shots into local empty directory.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f844b1b324c4a0bb4d098deac587289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.safetensors:   0%|          | 1.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/peulsilva/phrase-bert-setfit-2shots\n",
      "   f20ef01..05fde3d  main -> main\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/peulsilva/phrase-bert-setfit-2shots/commit/05fde3d7f712e14935bbe2c4298ff5fb0da03233'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"whaleloops/phrase-bert\")\n",
    "loss_fn = losses.CosineSimilarityLoss(model)\n",
    "cos_sim = torch.nn.CosineSimilarity(dim = 1)\n",
    "\n",
    "n_epochs = 10\n",
    "best_f1 = 0\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.fit(\n",
    "        train_objectives=[ (train_dataloader, loss_fn)],\n",
    "        epochs = 1,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "\n",
    "    y_true_val = torch.tensor([],device=device)\n",
    "    y_pred_val = torch.tensor([],device=device)\n",
    "\n",
    "    print(f\"Running validation after {epoch} epochs\")\n",
    "\n",
    "    for [x1, x2, y] in tqdm(val_dataloader):\n",
    "        with torch.no_grad():\n",
    "            v1 = model.encode(x1, convert_to_tensor= True)\n",
    "            v2 = model.encode(x2, convert_to_tensor= True)\n",
    "\n",
    "            cos = cos_sim(v1, v2)\n",
    "\n",
    "            y_pred = round(cos.item())\n",
    "            y_true = y\n",
    "\n",
    "            y_pred_val = torch.cat([\n",
    "                y_pred_val, \n",
    "                torch.tensor([y_pred]).to(device)\n",
    "            ])\n",
    "\n",
    "            y_true_val = torch.cat([\n",
    "                y_true_val, \n",
    "                torch.tensor([y_true]).to(device)\n",
    "            ])\n",
    "            \n",
    "    f1 = binary_f1_score(\n",
    "        y_pred_val,\n",
    "        y_true_val,\n",
    "    )\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = deepcopy(model)\n",
    "\n",
    "    conf_matrix= multiclass_confusion_matrix(\n",
    "        y_pred_val.to(torch.int64),\n",
    "        y_true_val.to(torch.int64),\n",
    "        num_classes=2\n",
    "    )\n",
    "\n",
    "    print(f'f1 score: {f1.item()}')\n",
    "    print(conf_matrix)\n",
    "\n",
    "best_model.save_to_hub(f\"peulsilva/phrase-bert-setfit-{n_shots}shots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLF(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features : int,\n",
    "        out_features : int, \n",
    "        *args, \n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.layer1 = torch.nn.Linear(in_features, 512)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(512, 256)\n",
    "        self.layer3 = torch.nn.Linear(256, out_features)\n",
    "\n",
    "    def forward(self, x : torch.Tensor):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu(x)\n",
    "        return self.layer3(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_n_shots_per_class(\n",
    "    train_text,\n",
    "    train_labels,\n",
    "    n_shots= n_shots,\n",
    "    num_classes= num_classes\n",
    ")\n",
    "X_val, y_val = get_n_shots_per_class(\n",
    "    val_text, \n",
    "    val_labels,\n",
    "    n_shots = 100,\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "def shuffle_two_lists(X, y ):\n",
    "    X_shuff = []\n",
    "    y_shuff = []\n",
    "    index_shuf = list(range(len(X)))\n",
    "    shuffle(index_shuf)\n",
    "    for i in index_shuf:\n",
    "        X_shuff.append(X[i])\n",
    "        y_shuff.append(y[i])\n",
    "\n",
    "\n",
    "    return X_shuff, y_shuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shuffled , y_train_shuffled = shuffle_two_lists(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Epoch: 99-----------\n",
      "f1 score: 0.7749999761581421\n",
      "tensor([[86,  2,  4,  8],\n",
      "        [ 5, 90,  0,  5],\n",
      "        [15,  4, 46, 35],\n",
      "        [ 4,  2,  6, 88]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(f\"peulsilva/phrase-bert-setfit-{n_shots}shots\")\\\n",
    "    .to(device)\n",
    "\n",
    "in_features = embedding_model.get_sentence_embedding_dimension()\n",
    "clf = CLF(\n",
    "    in_features,\n",
    "    num_classes,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    clf.parameters(),\n",
    "    lr = 1e-5\n",
    ")\n",
    "\n",
    "best_model = None\n",
    "best_f1 = 0\n",
    "n_epochs = 100\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in (range(n_epochs)):\n",
    "    for i in tqdm(range(len(X_train))):\n",
    "        text = X_train_shuffled[i]\n",
    "        label = torch.tensor(y_train_shuffled[i])\\\n",
    "            .to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = embedding_model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = clf(embedding)\n",
    "        loss = loss_fn(output, label)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    y_true_val = torch.tensor([],device=device)\n",
    "    y_pred_val = torch.tensor([],device=device)\n",
    "\n",
    "    for i in range(len(X_val)):\n",
    "        text = X_val[i]\n",
    "        label = torch.tensor(y_val[i])\\\n",
    "            .to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = embedding_model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "            y_pred = clf(embedding)\\\n",
    "                .argmax()\n",
    "            \n",
    "            y_pred_val = torch.cat([\n",
    "                y_pred_val, \n",
    "                torch.tensor([y_pred]).to(device)\n",
    "            ])\n",
    "\n",
    "            y_true_val = torch.cat([\n",
    "                y_true_val, \n",
    "                torch.tensor([y_val[i]]).to(device)\n",
    "            ])\n",
    "            \n",
    "    f1 = multiclass_f1_score(\n",
    "        y_pred_val,\n",
    "        y_true_val,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    \n",
    "    history.append(f1.item())\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = deepcopy(clf)\n",
    "\n",
    "    conf_matrix= multiclass_confusion_matrix(\n",
    "        y_pred_val.to(torch.int64),\n",
    "        y_true_val.to(torch.int64),\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    clear_output()\n",
    "    print(f\"---------Epoch: {epoch}-----------\")\n",
    "    print(f'f1 score: {f1.item()}')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 0\n",
    "for idx, f1 in enumerate(history):\n",
    "    if f1 == best_f1.item():\n",
    "        best_epoch = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'SetFit training results- AG news - 2 shots')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# history = ([k.to('cpu').numpy() for k in history])\n",
    "plt.plot(history)\n",
    "plt.scatter(\n",
    "    [best_epoch], \n",
    "    best_f1.item(),\n",
    "    color = \"green\",\n",
    "    label = f\"Best f1 : {round(best_f1.item(),3)}\"\n",
    ")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.tight_layout()\n",
    "plt.title(\"SetFit training results- AG news - 2 shots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_n_shots_per_class(\n",
    "    train_text,\n",
    "    train_labels,\n",
    "    n_shots= n_shots,\n",
    "    num_classes= num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = get_n_shots_per_class(\n",
    "    val_text, \n",
    "    val_labels,\n",
    "    n_shots = 10,\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_fit_data_train = SetFitDataset(\n",
    "    X_train,\n",
    "    y_train, \n",
    "    input_example_format= True\n",
    "    # R = 5\n",
    ")\n",
    "\n",
    "set_fit_data_val = SetFitDataset(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    # R = 5,\n",
    "    input_example_format= False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    set_fit_data_train.data,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    set_fit_data_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running validation after 0 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 124.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.5379877090454102\n",
      "tensor([[424, 176],\n",
      "        [ 49, 131]], device='cuda:0')\n",
      "Running validation after 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 122.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.5633074045181274\n",
      "tensor([[502,  98],\n",
      "        [ 71, 109]], device='cuda:0')\n",
      "Running validation after 2 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 120.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.5476922392845154\n",
      "tensor([[544,  56],\n",
      "        [ 91,  89]], device='cuda:0')\n",
      "Running validation after 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 121.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.4863014221191406\n",
      "tensor([[559,  41],\n",
      "        [109,  71]], device='cuda:0')\n",
      "Running validation after 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 120.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.4637681245803833\n",
      "tensor([[568,  32],\n",
      "        [116,  64]], device='cuda:0')\n",
      "Running validation after 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 120.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.42424240708351135\n",
      "tensor([[572,  28],\n",
      "        [124,  56]], device='cuda:0')\n",
      "Running validation after 6 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 120.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.41698843240737915\n",
      "tensor([[575,  25],\n",
      "        [126,  54]], device='cuda:0')\n",
      "Running validation after 7 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 121.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.40316203236579895\n",
      "tensor([[578,  22],\n",
      "        [129,  51]], device='cuda:0')\n",
      "Running validation after 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 119.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.39840638637542725\n",
      "tensor([[579,  21],\n",
      "        [130,  50]], device='cuda:0')\n",
      "Running validation after 9 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 120.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.3852458894252777\n",
      "tensor([[583,  17],\n",
      "        [133,  47]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Cloning https://huggingface.co/peulsilva/phrase-bert-setfit-5shots into local empty directory.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061d75df0eba4046aec356475fca289d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.safetensors:   0%|          | 1.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/peulsilva/phrase-bert-setfit-5shots\n",
      "   41426b9..89e647c  main -> main\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/peulsilva/phrase-bert-setfit-5shots/commit/89e647cccf0032a48572d2f1230671428d8ba0d7'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"whaleloops/phrase-bert\")\n",
    "loss_fn = losses.CosineSimilarityLoss(model)\n",
    "cos_sim = torch.nn.CosineSimilarity(dim = 1)\n",
    "\n",
    "n_epochs = 10\n",
    "best_f1 = 0\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.fit(\n",
    "        train_objectives=[ (train_dataloader, loss_fn)],\n",
    "        epochs = 1,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "\n",
    "    y_true_val = torch.tensor([],device=device)\n",
    "    y_pred_val = torch.tensor([],device=device)\n",
    "\n",
    "    print(f\"Running validation after {epoch} epochs\")\n",
    "\n",
    "    for [x1, x2, y] in tqdm(val_dataloader):\n",
    "        with torch.no_grad():\n",
    "            v1 = model.encode(x1, convert_to_tensor= True)\n",
    "            v2 = model.encode(x2, convert_to_tensor= True)\n",
    "\n",
    "            cos = cos_sim(v1, v2)\n",
    "\n",
    "            y_pred = round(cos.item())\n",
    "            y_true = y\n",
    "\n",
    "            y_pred_val = torch.cat([\n",
    "                y_pred_val, \n",
    "                torch.tensor([y_pred]).to(device)\n",
    "            ])\n",
    "\n",
    "            y_true_val = torch.cat([\n",
    "                y_true_val, \n",
    "                torch.tensor([y_true]).to(device)\n",
    "            ])\n",
    "            \n",
    "    f1 = binary_f1_score(\n",
    "        y_pred_val,\n",
    "        y_true_val,\n",
    "    )\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = deepcopy(model)\n",
    "\n",
    "    conf_matrix= multiclass_confusion_matrix(\n",
    "        y_pred_val.to(torch.int64),\n",
    "        y_true_val.to(torch.int64),\n",
    "        num_classes=2\n",
    "    )\n",
    "\n",
    "    print(f'f1 score: {f1.item()}')\n",
    "    print(conf_matrix)\n",
    "\n",
    "best_model.save_to_hub(f\"peulsilva/phrase-bert-setfit-{n_shots}shots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLF(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features : int,\n",
    "        out_features : int, \n",
    "        *args, \n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.layer1 = torch.nn.Linear(in_features, 512)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(512, 256)\n",
    "        self.layer3 = torch.nn.Linear(256, out_features)\n",
    "\n",
    "    def forward(self, x : torch.Tensor):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu(x)\n",
    "        return self.layer3(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_n_shots_per_class(\n",
    "    train_text,\n",
    "    train_labels,\n",
    "    n_shots= n_shots,\n",
    "    num_classes= num_classes\n",
    ")\n",
    "X_val, y_val = get_n_shots_per_class(\n",
    "    val_text, \n",
    "    val_labels,\n",
    "    n_shots = 100,\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "def shuffle_two_lists(X, y ):\n",
    "    X_shuff = []\n",
    "    y_shuff = []\n",
    "    index_shuf = list(range(len(X)))\n",
    "    shuffle(index_shuf)\n",
    "    for i in index_shuf:\n",
    "        X_shuff.append(X[i])\n",
    "        y_shuff.append(y[i])\n",
    "\n",
    "\n",
    "    return X_shuff, y_shuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shuffled , y_train_shuffled = shuffle_two_lists(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Epoch: 99-----------\n",
      "f1 score: 0.7225000262260437\n",
      "tensor([[72,  1, 18,  9],\n",
      "        [ 5, 86,  1,  8],\n",
      "        [ 2,  1, 44, 53],\n",
      "        [ 1,  0, 12, 87]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(f\"peulsilva/phrase-bert-setfit-{n_shots}shots\")\\\n",
    "    .to(device)\n",
    "\n",
    "in_features = embedding_model.get_sentence_embedding_dimension()\n",
    "clf = CLF(\n",
    "    in_features,\n",
    "    num_classes,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    clf.parameters(),\n",
    "    lr = 1e-5\n",
    ")\n",
    "\n",
    "best_model = None\n",
    "best_f1 = 0\n",
    "n_epochs = 100\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in (range(n_epochs)):\n",
    "    for i in tqdm(range(len(X_train))):\n",
    "        text = X_train_shuffled[i]\n",
    "        label = torch.tensor(y_train_shuffled[i])\\\n",
    "            .to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = embedding_model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = clf(embedding)\n",
    "        loss = loss_fn(output, label)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    y_true_val = torch.tensor([],device=device)\n",
    "    y_pred_val = torch.tensor([],device=device)\n",
    "\n",
    "    for i in range(len(X_val)):\n",
    "        text = X_val[i]\n",
    "        label = torch.tensor(y_val[i])\\\n",
    "            .to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = embedding_model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "            y_pred = clf(embedding)\\\n",
    "                .argmax()\n",
    "            \n",
    "            y_pred_val = torch.cat([\n",
    "                y_pred_val, \n",
    "                torch.tensor([y_pred]).to(device)\n",
    "            ])\n",
    "\n",
    "            y_true_val = torch.cat([\n",
    "                y_true_val, \n",
    "                torch.tensor([y_val[i]]).to(device)\n",
    "            ])\n",
    "            \n",
    "    f1 = multiclass_f1_score(\n",
    "        y_pred_val,\n",
    "        y_true_val,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    \n",
    "    history.append(f1.item())\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = deepcopy(clf)\n",
    "\n",
    "    conf_matrix= multiclass_confusion_matrix(\n",
    "        y_pred_val.to(torch.int64),\n",
    "        y_true_val.to(torch.int64),\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    clear_output()\n",
    "    print(f\"---------Epoch: {epoch}-----------\")\n",
    "    print(f'f1 score: {f1.item()}')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 0\n",
    "for idx, f1 in enumerate(history):\n",
    "    if f1 == best_f1.item():\n",
    "        best_epoch = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'SetFit training results- AG news - 5 shots')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# history = ([k.to('cpu').numpy() for k in history])\n",
    "plt.plot(history)\n",
    "plt.scatter(\n",
    "    [best_epoch], \n",
    "    best_f1.item(),\n",
    "    color = \"green\",\n",
    "    label = f\"Best f1 : {round(best_f1.item(),3)}\"\n",
    ")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.tight_layout()\n",
    "plt.title(\"SetFit training results- AG news - 5 shots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_n_shots_per_class(\n",
    "    train_text,\n",
    "    train_labels,\n",
    "    n_shots= n_shots,\n",
    "    num_classes= num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = get_n_shots_per_class(\n",
    "    val_text, \n",
    "    val_labels,\n",
    "    n_shots = 10,\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_fit_data_train = SetFitDataset(\n",
    "    X_train,\n",
    "    y_train, \n",
    "    input_example_format= True\n",
    "    # R = 5\n",
    ")\n",
    "\n",
    "set_fit_data_val = SetFitDataset(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    # R = 5,\n",
    "    input_example_format= False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    set_fit_data_train.data,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    set_fit_data_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running validation after 0 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 123.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.3613445460796356\n",
      "tensor([[585,  15],\n",
      "        [137,  43]], device='cuda:0')\n",
      "Running validation after 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 121.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.540145993232727\n",
      "tensor([[580,  20],\n",
      "        [106,  74]], device='cuda:0')\n",
      "Running validation after 2 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 121.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.6538461446762085\n",
      "tensor([[570,  30],\n",
      "        [ 78, 102]], device='cuda:0')\n",
      "Running validation after 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 121.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.650306761264801\n",
      "tensor([[560,  40],\n",
      "        [ 74, 106]], device='cuda:0')\n",
      "Running validation after 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 121.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.6726190447807312\n",
      "tensor([[557,  43],\n",
      "        [ 67, 113]], device='cuda:0')\n",
      "Running validation after 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 120.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.6882352828979492\n",
      "tensor([[557,  43],\n",
      "        [ 63, 117]], device='cuda:0')\n",
      "Running validation after 6 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 121.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7005649209022522\n",
      "tensor([[550,  50],\n",
      "        [ 56, 124]], device='cuda:0')\n",
      "Running validation after 7 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 120.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7122506499290466\n",
      "tensor([[554,  46],\n",
      "        [ 55, 125]], device='cuda:0')\n",
      "Running validation after 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 120.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7048709988594055\n",
      "tensor([[554,  46],\n",
      "        [ 57, 123]], device='cuda:0')\n",
      "Running validation after 9 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:06<00:00, 120.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7106016874313354\n",
      "tensor([[555,  45],\n",
      "        [ 56, 124]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Cloning https://huggingface.co/peulsilva/phrase-bert-setfit-10shots into local empty directory.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddee555fdacd4481954d1bfe480b3711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.safetensors:   0%|          | 1.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/peulsilva/phrase-bert-setfit-10shots\n",
      "   7950fac..b2f78f7  main -> main\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/peulsilva/phrase-bert-setfit-10shots/commit/b2f78f7d3505a75fe122586bf722a7c605b1eddd'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"whaleloops/phrase-bert\")\n",
    "loss_fn = losses.CosineSimilarityLoss(model)\n",
    "cos_sim = torch.nn.CosineSimilarity(dim = 1)\n",
    "\n",
    "n_epochs = 10\n",
    "best_f1 = 0\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.fit(\n",
    "        train_objectives=[ (train_dataloader, loss_fn)],\n",
    "        epochs = 1,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "\n",
    "    y_true_val = torch.tensor([],device=device)\n",
    "    y_pred_val = torch.tensor([],device=device)\n",
    "\n",
    "    print(f\"Running validation after {epoch} epochs\")\n",
    "\n",
    "    for [x1, x2, y] in tqdm(val_dataloader):\n",
    "        with torch.no_grad():\n",
    "            v1 = model.encode(x1, convert_to_tensor= True)\n",
    "            v2 = model.encode(x2, convert_to_tensor= True)\n",
    "\n",
    "            cos = cos_sim(v1, v2)\n",
    "\n",
    "            y_pred = round(cos.item())\n",
    "            y_true = y\n",
    "\n",
    "            y_pred_val = torch.cat([\n",
    "                y_pred_val, \n",
    "                torch.tensor([y_pred]).to(device)\n",
    "            ])\n",
    "\n",
    "            y_true_val = torch.cat([\n",
    "                y_true_val, \n",
    "                torch.tensor([y_true]).to(device)\n",
    "            ])\n",
    "            \n",
    "    f1 = binary_f1_score(\n",
    "        y_pred_val,\n",
    "        y_true_val,\n",
    "    )\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = deepcopy(model)\n",
    "\n",
    "    conf_matrix= multiclass_confusion_matrix(\n",
    "        y_pred_val.to(torch.int64),\n",
    "        y_true_val.to(torch.int64),\n",
    "        num_classes=2\n",
    "    )\n",
    "\n",
    "    print(f'f1 score: {f1.item()}')\n",
    "    print(conf_matrix)\n",
    "\n",
    "best_model.save_to_hub(f\"peulsilva/phrase-bert-setfit-{n_shots}shots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLF(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features : int,\n",
    "        out_features : int, \n",
    "        *args, \n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.layer1 = torch.nn.Linear(in_features, 512)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(512, 256)\n",
    "        self.layer3 = torch.nn.Linear(256, out_features)\n",
    "\n",
    "    def forward(self, x : torch.Tensor):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu(x)\n",
    "        return self.layer3(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_n_shots_per_class(\n",
    "    train_text,\n",
    "    train_labels,\n",
    "    n_shots= n_shots,\n",
    "    num_classes= num_classes\n",
    ")\n",
    "X_val, y_val = get_n_shots_per_class(\n",
    "    val_text, \n",
    "    val_labels,\n",
    "    n_shots = 100,\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "def shuffle_two_lists(X, y ):\n",
    "    X_shuff = []\n",
    "    y_shuff = []\n",
    "    index_shuf = list(range(len(X)))\n",
    "    shuffle(index_shuf)\n",
    "    for i in index_shuf:\n",
    "        X_shuff.append(X[i])\n",
    "        y_shuff.append(y[i])\n",
    "\n",
    "\n",
    "    return X_shuff, y_shuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shuffled , y_train_shuffled = shuffle_two_lists(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Epoch: 52-----------\n",
      "f1 score: 0.8475000262260437\n",
      "tensor([[85,  1, 12,  2],\n",
      "        [12, 86,  1,  1],\n",
      "        [ 3,  0, 82, 15],\n",
      "        [ 6,  0,  8, 86]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 216.17it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb Cell 67\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(y_val[i])\\\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m     embedding \u001b[39m=\u001b[39m embedding_model\u001b[39m.\u001b[39;49mencode(text, convert_to_tensor\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m clf(embedding)\\\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m         \u001b[39m.\u001b[39margmax()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     y_pred_val \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m         y_pred_val, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m         torch\u001b[39m.\u001b[39mtensor([y_pred])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.104.254.97/users/eleves-a/2022/pedro.silva/few-shot-learning-transformers/notebooks/few_shot_text_classification/setfit/01-train_setfit.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     ])\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1006\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1007\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1008\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1012\u001b[0m )\n\u001b[0;32m-> 1013\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1014\u001b[0m     embedding_output,\n\u001b[1;32m   1015\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1016\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1017\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1018\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1019\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1020\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1021\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1022\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1023\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1024\u001b[0m )\n\u001b[1;32m   1025\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1026\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    596\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    597\u001b[0m         layer_module\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    598\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         output_attentions,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    608\u001b[0m         hidden_states,\n\u001b[1;32m    609\u001b[0m         attention_mask,\n\u001b[1;32m    610\u001b[0m         layer_head_mask,\n\u001b[1;32m    611\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    612\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    613\u001b[0m         past_key_value,\n\u001b[1;32m    614\u001b[0m         output_attentions,\n\u001b[1;32m    615\u001b[0m     )\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    498\u001b[0m         hidden_states,\n\u001b[1;32m    499\u001b[0m         attention_mask,\n\u001b[1;32m    500\u001b[0m         head_mask,\n\u001b[1;32m    501\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    502\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/transformers/models/bert/modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 427\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    428\u001b[0m         hidden_states,\n\u001b[1;32m    429\u001b[0m         attention_mask,\n\u001b[1;32m    430\u001b[0m         head_mask,\n\u001b[1;32m    431\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    432\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    433\u001b[0m         past_key_value,\n\u001b[1;32m    434\u001b[0m         output_attentions,\n\u001b[1;32m    435\u001b[0m     )\n\u001b[1;32m    436\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/few-shot-learning-transformers/.venv/lib64/python3.9/site-packages/transformers/models/bert/modeling_bert.py:365\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     attention_probs \u001b[39m=\u001b[39m attention_probs \u001b[39m*\u001b[39m head_mask\n\u001b[0;32m--> 365\u001b[0m context_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(attention_probs, value_layer)\n\u001b[1;32m    367\u001b[0m context_layer \u001b[39m=\u001b[39m context_layer\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    368\u001b[0m new_context_layer_shape \u001b[39m=\u001b[39m context_layer\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_head_size,)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(f\"peulsilva/phrase-bert-setfit-{n_shots}shots\")\\\n",
    "    .to(device)\n",
    "\n",
    "in_features = embedding_model.get_sentence_embedding_dimension()\n",
    "clf = CLF(\n",
    "    in_features,\n",
    "    num_classes,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    clf.parameters(),\n",
    "    lr = 1e-5\n",
    ")\n",
    "\n",
    "best_model = None\n",
    "best_f1 = 0\n",
    "n_epochs = 100\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in (range(n_epochs)):\n",
    "    for i in tqdm(range(len(X_train))):\n",
    "        text = X_train_shuffled[i]\n",
    "        label = torch.tensor(y_train_shuffled[i])\\\n",
    "            .to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = embedding_model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = clf(embedding)\n",
    "        loss = loss_fn(output, label)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    y_true_val = torch.tensor([],device=device)\n",
    "    y_pred_val = torch.tensor([],device=device)\n",
    "\n",
    "    for i in range(len(X_val)):\n",
    "        text = X_val[i]\n",
    "        label = torch.tensor(y_val[i])\\\n",
    "            .to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = embedding_model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "            y_pred = clf(embedding)\\\n",
    "                .argmax()\n",
    "            \n",
    "            y_pred_val = torch.cat([\n",
    "                y_pred_val, \n",
    "                torch.tensor([y_pred]).to(device)\n",
    "            ])\n",
    "\n",
    "            y_true_val = torch.cat([\n",
    "                y_true_val, \n",
    "                torch.tensor([y_val[i]]).to(device)\n",
    "            ])\n",
    "            \n",
    "    f1 = multiclass_f1_score(\n",
    "        y_pred_val,\n",
    "        y_true_val,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    \n",
    "    history.append(f1.item())\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = deepcopy(clf)\n",
    "\n",
    "    conf_matrix= multiclass_confusion_matrix(\n",
    "        y_pred_val.to(torch.int64),\n",
    "        y_true_val.to(torch.int64),\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    clear_output()\n",
    "    print(f\"---------Epoch: {epoch}-----------\")\n",
    "    print(f'f1 score: {f1.item()}')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 0\n",
    "for idx, f1 in enumerate(history):\n",
    "    if f1 == best_f1.item():\n",
    "        best_epoch = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'SetFit training results- AG news - 10 shots')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHsCAYAAABfQeBBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbi0lEQVR4nO3deXhTVf7H8U+SbpS2lLUtUCj7vm8CIiBLVQRxGRY3BMGZARRBnBEVC4jiiAvqTwdHER0VQRB3RCqCIiIgDAhYEJCdQlmElpa2aXN/f0ACsS20kJuk4f16njyam3tzT3Ja+PA995xrMQzDEAAAAEo9q68bAAAAAM8g2AEAAAQIgh0AAECAINgBAAAECIIdAABAgCDYAQAABAiCHQAAQIAg2AEAAAQIgh0AAECAINgBJZCQkKB77rnH180oksVi0aRJky7pWH//bN50Od8jUFzLly+XxWLRggULfN0UBBCCHfzepk2bdNttt6lmzZoKCwtTtWrV1KtXL73yyiuX9H5z5szRjBkzCmzfvXu3LBZLoY+rrrqq0Pf69ddfNWnSJO3evbtY5160aBGBoRT68ccfNWnSJJ04ccJr5zxx4oTCwsJksViUkpJS5H4Oh0P//e9/1atXL1WqVEnBwcGqUqWKevfurf/85z/KycnxWptLi6eeekr9+vVTTEzMRUP8gQMHNGDAAEVHRysqKko33XSTfv/9d+81toT4MwZBvm4AcCE//vijunfvrho1amjEiBGKjY3Vvn379NNPP+mll17S/fffX+L3nDNnjjZv3qwHH3yw0NcHDx6sG264wW1b5cqVJUnbtm2T1Xru30O//vqrJk+erG7duikhIeGi5160aJFeffVV0/7gPX36tIKCLu3X+s+fDef8+OOPmjx5su655x5FR0d75Zzz58+XxWJRbGys3n//fU2dOrXAPqdPn9bNN9+sr7/+Wp06ddL48eMVExOj48eP67vvvtPIkSO1evVqzZo1yyttLi0ef/xxxcbGqlWrVvr666+L3O/UqVPq3r27Tp48qUcffVTBwcF68cUX1bVrV23YsEEVK1b0YquLx+w/Y+D/CHbwa0899ZTKlSuntWvXFvgLNS0tzZRztm7dWnfeeWehr4WGhppyzsLk5eXJ4XAoJCSk2MeEhYVd8vm8+dku5lI+e6B57733dMMNN6hmzZqaM2dOocFu7Nix+vrrrzVjxgyNGTPG7bWHHnpI27dvV3JysreaXGrs2rVLCQkJOnr0qOsfbYV57bXXtH37dq1Zs0bt2rWTJF1//fVq2rSpnn/+eT399NPeajJQfAbgxxo0aGB069at2Pu/++67RuvWrY2wsDCjfPnyxsCBA429e/e6Xu/atashye1Rs2ZNwzAMY9euXYYkY/r06UW+f82aNY0hQ4YYhmEYs2fPLvBekoxly5YVeuyQIUMK3f/P537xxReN2rVrG1ar1fjf//5n5OTkGBMnTjRat25tREVFGeHh4cbVV19tfPvttwXOIclISkpyPU9KSjIkGdu3bzeGDBlilCtXzoiKijLuueceIzMzs8jPdv7n++GHH4yxY8calSpVMsLDw43+/fsbaWlpbsfm5+cbSUlJRlxcnFGmTBmjW7duxpYtWwq8Z2Eu9NkNwzBSUlKMW2+91ShfvrwRGhpqtGnTxvj000/d3iM3N9eYNGmSUbduXSM0NNSoUKGC0blzZ2PJkiWufbp27Wp07dq10H5x/gwU9j06v8M/P3bt2mUYhmEsWbLE6Ny5s1GuXDmjbNmyRv369Y0JEyZc8DNfzJ49ewyLxWJ8+OGHxurVqw1JxsqVK9322bt3r2Gz2Yzrrrvuss5lGGf6vk+fPsaKFSuMdu3aGaGhoUatWrWMd955p8C+f/zxhzFmzBijevXqRkhIiFGnTh3jmWeeMfLz8137tGrVyrj55pvdjmvatKkhydi4caNr29y5cw1Jxq+//moYhmGkp6cbY8aMMWrWrGmEhIQYlStXNnr27GmsW7fusj9jYY4cOVLgd+Z87dq1M9q1a1dge+/evY06depc9P0v9rOxbNkyQ5Ixb948Y+rUqUa1atWM0NBQ49prrzW2b99e4P0+/PBD159vFStWNO644w5j//79rtcv9GeMYRjGBx98YLRu3dqIiIgwIiMjjaZNmxozZsy46OdA6ULFDn6tZs2aWrVqlTZv3qymTZtecN+nnnpKEydO1IABAzR8+HAdOXJEr7zyiq655hr973//U3R0tB577DGdPHlS+/fv14svvihJioiIcHufrKwsHT161G1buXLlFBwc7Lbtmmuu0QMPPKCXX35Zjz76qBo1aiRJrv/+2V//+lcdPHhQycnJevfddwvdZ/bs2crOztZ9992n0NBQVahQQenp6XrzzTc1ePBgjRgxQhkZGZo1a5YSExO1Zs0atWzZ8oLfiyQNGDBAtWrV0rRp07R+/Xq9+eabqlKliv71r39d9Nj7779f5cuXV1JSknbv3q0ZM2Zo9OjRmjdvnmufCRMm6Nlnn1Xfvn2VmJiojRs3KjExUdnZ2Rd9/wt99i1btqhz586qVq2aHnnkEZUtW1Yffvih+vfvr48++kg333yzJGnSpEmaNm2ahg8frvbt2ys9PV0///yz1q9fr169ehW7DYW55ZZb9Ntvv+mDDz7Qiy++qEqVKkk6Mzy/ZcsW3XjjjWrevLmmTJmi0NBQ7dixQytXrrysc37wwQcqW7asbrzxRpUpU0Z16tTR+++/r06dOrn2+eqrr5Sfn19kdbmkduzYodtuu0333nuvhgwZorfeekv33HOP2rRpoyZNmkg687vRtWtXHThwQH/9619Vo0YN/fjjj5owYYJSU1Nd16526dJFH3zwgeu9jx8/ri1btshqtWrFihVq3ry5JGnFihWqXLmy63fmb3/7mxYsWKDRo0ercePGOnbsmH744QelpKSodevWHvmcxeVwOPTLL79o2LBhBV5r3769lixZooyMDEVGRhZ6fEl+Np555hlZrVaNHz9eJ0+e1LPPPqs77rhDq1evdu3z9ttva+jQoWrXrp2mTZumw4cP66WXXtLKlStdf75d6M+Y5ORkDR48WD169HD93qekpGjlypUFqr0o5XydLIELWbJkiWGz2QybzWZ07NjR+Mc//mF8/fXXRm5urtt+u3fvNmw2m/HUU0+5bd+0aZMRFBTktr1Pnz4FKjSGca5yVNjDWYX7cwVq/vz5F6zS/dmoUaOMwn7tnOeOiooqUA3Ly8szcnJy3Lb98ccfRkxMjDFs2DC37SqiYvfn/W6++WajYsWKbtuKqtj17NnTcDgcru1jx441bDabceLECcMwDOPQoUNGUFCQ0b9/f7f3mzRpkiGp2BW7wj57jx49jGbNmhnZ2dmubQ6Hw+jUqZNRr14917YWLVoYffr0ueB5LrViZxiGMX36dLcqndOLL75oSDKOHDlywXOXVLNmzYw77rjD9fzRRx81KlWqZNjtdte2sWPHGpKMDRs2uB2bk5NjHDlyxPU4evToRc9Xs2ZNQ5Lx/fffu7alpaUZoaGhxkMPPeTa9uSTTxply5Y1fvvtN7fjH3nkEcNms7mq487fC2cl7rPPPjNCQ0ONfv36GQMHDnQd17x5c7fKXrly5YxRo0ZdtL2ecqGKnfO1KVOmFHjt1VdfNSQZW7duLfK9i/Oz4azYNWrUyO13/KWXXjIkGZs2bTIM40xFukqVKkbTpk2N06dPu/b74osvDEnGE0884dpW1J8xY8aMMaKiooy8vLwi24PAwJXS8Gu9evXSqlWr1K9fP23cuFHPPvusEhMTVa1aNX322Weu/RYuXCiHw6EBAwbo6NGjrkdsbKzq1aunZcuWFfuc9913n5KTk90eLVq0MOPjFXDrrbcWuObHZrO5rjVzOBw6fvy48vLy1LZtW61fv75Y7/u3v/3N7XmXLl107NgxpaenX/TY++67TxaLxe3Y/Px87dmzR5K0dOlS5eXlaeTIkW7HlXRiy58/+/Hjx/Xtt99qwIABysjIcPXpsWPHlJiYqO3bt+vAgQOSpOjoaG3ZskXbt28v0Tkvl/O6z08//VQOh8Mj7/nLL79o06ZNGjx4sGvb4MGDdfToUbcL/Z199+eK86JFi1S5cmXXo2bNmsU6b+PGjdWlSxfX88qVK6tBgwZuM0Dnz5+vLl26qHz58m6/Zz179lR+fr6+//57SXK9j/P5ihUr1K5dO/Xq1UsrVqyQdGbW7+bNm93OGR0drdWrV+vgwYPFarOZTp8+Lanwa0+d17I69ylMSX42hg4d6nY9qfM7cX73P//8s9LS0jRy5Ei362j79Omjhg0b6ssvv7zo54mOjlZmZibXXF4BCHbwe+3atdPChQv1xx9/aM2aNZowYYIyMjJ022236ddff5Ukbd++XYZhqF69em5/qVWuXFkpKSklmmhRr1499ezZ0+1Rvnx5sz6em1q1ahW6/Z133lHz5s0VFhamihUrqnLlyvryyy918uTJYr1vjRo13J47P88ff/xx2cc6A17dunXd9qtQoUKJvrc/f/YdO3bIMAxNnDixQJ8mJSVJOjeBZsqUKTpx4oTq16+vZs2a6eGHH9Yvv/xS7HNfqoEDB6pz584aPny4YmJiNGjQIH344Yduf5EfOnTI7XGhMCCdmTRRtmxZ1a5dWzt27NCOHTsUFhamhIQEvf/++679nEOAp06dcju+c+fOrn+Q9O7du9if5c/9LJ3p6/N/RrZv367FixcX6I+ePXtKOtcfMTExqlevnivErVixQl26dNE111yjgwcP6vfff9fKlSvlcDjcgt2zzz6rzZs3Kz4+Xu3bt9ekSZMuurRIbm5uge84Pz+/2J+7KGXKlJGkQpeLcV5i4NynMMX52XAq7u9YgwYNChzbsGFD1+sXMnLkSNWvX1/XX3+9qlevrmHDhmnx4sUXPQ6lD9fYodQICQlRu3bt1K5dO9WvX19Dhw7V/PnzlZSUJIfDIYvFoq+++ko2m63AsX+uavirwv6ieO+993TPPfeof//+evjhh1WlShXZbDZNmzZNO3fuLNb7FvadSJJhGKYeWxJ//uzOvwDHjx+vxMTEQo9xhslrrrlGO3fu1KeffqolS5bozTff1IsvvqiZM2dq+PDhks4sOlxYmy8nBJQpU0bff/+9li1bpi+//FKLFy/WvHnzdO2112rJkiWy2WyKi4tzO2b27NlFLgRtGIY++OADZWZmqnHjxgVeT0tL06lTpxQREaGGDRtKkjZv3uxWUT4/aL333nvF/izF6WeHw6FevXrpH//4R6H71q9f3/X/V199tZYuXarTp09r3bp1euKJJ9S0aVNFR0drxYoVSklJUUREhFq1auU6ZsCAAerSpYs+/vhjLVmyRNOnT9e//vUvLVy4UNdff32h53QuiXQ+56zXy1GhQgWFhoYqNTW1wGvObVWrVi3y+OL8bDh543esSpUq2rBhg77++mt99dVX+uqrrzR79mzdfffdeueddzx2HvgewQ6lUtu2bSWd+wO2Tp06MgxDtWrVcvvLpTDnDyterpK+16Wce8GCBapdu7YWLlzodryzauVrzqG+HTt2uFXdjh07VqyKYFFq164tSQoODnYFlQupUKGChg4dqqFDh+rUqVO65pprNGnSJFewK1++fKHVn+JUOy7Ub1arVT169FCPHj30wgsv6Omnn9Zjjz2mZcuWqWfPngWGvpwTEQrz3Xffaf/+/ZoyZUqBSTh//PGH7rvvPn3yySe68847df3118tms+n999/XHXfccdHP4Al16tTRqVOnitUfXbp00ezZszV37lzl5+erU6dOslqtuvrqq13BrlOnTgVCTVxcnEaOHKmRI0cqLS1NrVu31lNPPVVksGvRokWB7zg2NvbSP+RZVqtVzZo1088//1zgtdWrV6t27dpFTpw4/z0u9LNRXM7fsW3btunaa691e23btm1uw+0X+lkNCQlR37591bdvXzkcDo0cOVKvv/66Jk6cWKDijtKLoVj4tWXLlhX6r9ZFixZJOjc0ccstt8hms2ny5MkF9jcMQ8eOHXM9L1u2bLGHMC+mbNmyklTsOxKUdH/p3L/mz/9cq1ev1qpVq4r9Hmbq0aOHgoKC9O9//9tt+//93/9d1vtWqVJF3bp10+uvv15o1eTIkSOu/z+/f6UzFdq6deu6DaPVqVNHW7dudTtu48aNxZrBWlS/HT9+vMC+zlnKznP/eVj/zxW88zmHYR9++GHddtttbo8RI0aoXr16ruHYGjVqaNiwYfrqq6+K/K49XVUdMGCAVq1aVeiividOnFBeXp7ruXOI9V//+peaN2+ucuXKubYvXbpUP//8s9swbH5+foHfyypVqqhq1aoXvHtG+fLlC3zHl7Oe4/luu+02rV271i3cbdu2Td9++63+8pe/XPDY4vxsFFfbtm1VpUoVzZw50+3Yr776SikpKerTp49rW1E/q3/+HbFara7ZydydJLBQsYNfu//++5WVlaWbb75ZDRs2VG5urn788UfNmzdPCQkJGjp0qKQzf2lPnTpVEyZM0O7du9W/f39FRkZq165d+vjjj3Xfffdp/PjxkqQ2bdpo3rx5GjdunNq1a6eIiAj17dv3ktrXsmVL2Ww2/etf/9LJkycVGhqqa6+9VlWqVCl0/zZt2kiSHnjgASUmJspms2nQoEEXPMeNN96ohQsX6uabb1afPn20a9cuzZw5U40bNy5wfZUvxMTEaMyYMXr++efVr18/XXfdddq4caO++uorVapU6bIqpK+++qquvvpqNWvWTCNGjFDt2rV1+PBhrVq1Svv379fGjRslnbnwv1u3bmrTpo0qVKign3/+2bVshtOwYcP0wgsvKDExUffee6/S0tI0c+ZMNWnS5KKTSJz99thjj2nQoEEKDg5W3759NWXKFH3//ffq06ePatasqbS0NL322muqXr26rr766hJ91pycHH300Ufq1atXkcGkX79+eumll5SWlqYqVapoxowZ2rVrl+6//37NnTtXffv2VZUqVXT06FGtXLlSn3/+eaHXZV2qhx9+WJ999pluvPFG11IomZmZ2rRpkxYsWKDdu3e7loOpW7euYmNjtW3bNreJNNdcc43++c9/SpJbsMvIyFD16tV12223qUWLFoqIiNA333yjtWvX6vnnn/fYZ5Ckd999V3v27FFWVpakM5M8nAtA33XXXa4K2MiRI/XGG2+oT58+Gj9+vIKDg/XCCy8oJiZGDz300AXP4cmfjeDgYP3rX//S0KFD1bVrVw0ePNi13ElCQoLGjh3r2reoP2OGDx+u48eP69prr1X16tW1Z88evfLKK2rZsmWRSzShlPLFVFyguL766itj2LBhRsOGDY2IiAgjJCTEqFu3rnH//fcbhw8fLrD/Rx99ZFx99dVG2bJljbJlyxoNGzY0Ro0aZWzbts21z6lTp4zbb7/diI6OvqwFip3eeOMNo3bt2obNZrvo0id5eXnG/fffb1SuXNmwWCyFLlD8Zw6Hw3j66aeNmjVrGqGhoUarVq2ML774oljLdDiXO/nzkgvOpUzOX76jqOVO1q5d63asc4mG8z9nXl6eMXHiRCM2NtYoU6aMce211xopKSlGxYoVjb/97W9Ffh8X++yGYRg7d+407r77biM2NtYIDg42qlWrZtx4443GggULXPtMnTrVaN++vREdHW2UKVPGaNiwofHUU08VWBbnvffeM2rXrm2EhIQYLVu2NL7++utifY+GcWapj2rVqhlWq9X13S1dutS46aabjKpVqxohISFG1apVjcGDBxdYDqQ4PvroI0OSMWvWrCL3Wb58uSHJeOmll1zb8vLyjNmzZxvXXnutUaFCBSMoKMioVKmS0aNHD2PmzJluy2MUxblA8Z8VtkRMRkaGMWHCBKNu3bpGSEiIUalSJaNTp07Gc889V+D7/stf/uJagNcpNzfXCA8PN0JCQtzalpOTYzz88MNGixYtjMjISKNs2bJGixYtjNdee+2i7S+pwhYqdz7+/Pu7b98+47bbbjOioqKMiIgI48Ybbyx08eA/K87PhvN3af78+W7HOn8nZs+e7bZ93rx5RqtWrVyLcP95gWLDKPrPmAULFhi9e/c2qlSpYoSEhBg1atQw/vrXvxqpqakl+OZQGlgMw8O1egDQmaGg8uXLa+rUqXrsscd83RwAuCJwjR2Ay1bYEh7OuxB069bNu40BgCsY19gBuGzz5s3T22+/rRtuuEERERH64Ycf9MEHH6h3797q3Lmzr5sHAFcMgh2Ay9a8eXMFBQXp2WefVXp6umtChfOCdACAd3CNHQAAQIDgGjsAAIAAQbADAAAIEFfcNXYOh0MHDx5UZGSkR28tBQAAYAbDMJSRkaGqVavKar1wTe6KC3YHDx5UfHy8r5sBAABQIvv27VP16tUvuM8VF+ycN23et2+foqKiTDuP3W7XkiVL1Lt3bwUHB5t2HhSNPvAP9IN/oB98jz7wD6WxH9LT0xUfH+/KMBdyxQU75/BrVFSU6cEuPDxcUVFRpeYHJ9DQB/6BfvAP9IPv0Qf+oTT3Q3EuIWPyBAAAQIAg2AEAAAQIgh0AAECAINgBAAAECIIdAABAgCDYAQAABAiCHQAAQIAg2AEAAAQIgh0AAECAINgBAAAEiCvulmLA+fId+Vqxd4VSM1IVFxmnLjW6yGa1+bpZAABcEoIdrlgLUxZqzOIx2p++37WtelR1vXTdS7ql0S0+bBkAAJeGoVhckRamLNRtH97mFuok6UD6Ad324W1amLLQRy0DAODSEexwxcl35GvM4jEyZBR4zbntwcUPKt+R7+2mAQBwWQh2uOKs2LtC+9P3y2pEKyy/taLstyrKfrNsjiqSzoS7fen7tGLvCh+3FACAkuEaOwQ8e75DO4+lKyU1XSmpGfr2t5Oqfvpd2VTebb/yefcq27pJp2zfKsv2g1IzUn3UYgAALg3BDgHlRFaufj0b4LYcOKE1v9k0fs1S2fPPH3YNkk3lZcihPMsB5Vp3yWqUU5ijmevhsP9Nn64OV1xImq6uW0lBNorbAAD/R7BDqZTvMLTraKZSUtO19dCZIJeSmq7Uk9l/2tMiyVBEaJAaxUWqUVyUGsRG6JHv7tLBrJ/lsJzb3+aopLL53RSR30PBRrx+2pGvn3asVeXIUPVvWVW3tqmuhrFRXv2cAACUBMEOfi8j266thzLODqWm69fUDG07lK5su6PQ/WtUCFfD2Eg1iCmrzAPbdeeNXVWrcpQsFotrnzJRY3Xbh7fJIotrwkS+9agyrB8pI+gjvdjjI/3xR319uuGAjmTk6I0Vu/TGil1qFBelW1tXU7+WVVUlMswrnx8AgOIi2MFvGIahfcdPnx1KPfs4lK59x08Xun+ZYJsaxJ6pwjV2VeMiFRkWLEmy2+1atOg3xZcPdwt1knRLo1u0YMCCQtexm3HdDN3S6GZJ0qM3NNLybWlauP6Alm49rJTUdE39Ml3Tvtqqa+pV0i2tq6tX4xiFBbOoMQDA9wh28Ims3DxtO5ThGkI9M6SaoVM5eYXuH1cuTI3iolzDqY3jolSzYlnZrJZC9y+OWxrdopsa3HTBO0+EBFnVu0msejeJ1YmsXH3+S6oWrt+v/+09oWXbjmjZtiOKDA1Sn+ZxuqV1dbVLKF8gRAIA4C0EO5jKMAylnsw+V4E7G+R2HcuUUXAZOYXYrKoXE3E2xJ0NcrFRKl82xJT22aw2dUvoVqx9o8NDdNdVNXXXVTX1+5FT+vh/B7Rw/QEdOHFac9fu09y1+xRfoYxubllN8RXCTWmvt9isFtWuHKEGMZEqE0I18kqQlZunrYcytPtopvIdhfxy4rLl5+frlzSLTq8/IJuN3ytfMaMfalQIV4faFT3yXpeLYAePycnL1/bDp9yGUrceytCJLHuh+1eKCFWjuEg1doW4KNWuXFbBpWAGau3KEXqodwON7Vlfa3Yf18L1+7Vo0yHtO35aL3+7w9fN8xirRUqoVNZVJXVWTGOjwqhMllKGYejgidNu/9j6NTVdu4v4xxY8zaY5O7f4uhHwcD/c1LIqwQ6l25GMnPP+Yjjzl8POI6eUV8i/9G1Wi+pULnteFe5MQAiEyQdWq0VX1a6oq2pX1OR+TbXk10NasuWwsnILH1IuLbLtDm1Py9DRU7n6/Uimfj+SqS9/ObeuX/nwYDWKi1JCpbIKushwuMPh0J7dVq39IkVWq/+H9kCVm5evn7dZlbRhuU6cLvofW/VjIhQaRD+ZwWEYOpKWpspVqsjKP4x8xox+aBznPysmEOxwQfZ8h34/knnejNQzIe7oqZxC9y9XJthV1XFWeepWibgiJheUCbHpppbVdFPLar5uisekZWS7XQeZkpqunUcy9UeWXT/uPKYfdx4r5jtZteLwPlPbiuKwSrLLZrWobuUIt9/VRnFRqhwZ6usGBrQzE7oW6YYbWis4ONjXzbliBXo/EOyuMIfTszXl81+1/0ThM03Pl2PP1+9HMpWbX3BZEYtFqlXxTBWuYWykGlc98xdDXDmG6AJJlcgwVYkMU9f6lV3bsu1nhtxTUtOL9XPkyM/X9h07VK9uXVm5rshnDEe+ju7droG9O6tRtWiFBtEXQCAi2F1BTp626+5Za7TtcEaJjisbYiswjNogNlLhIfz4XInCgm1qVr2cmlUvV6z97Xa7FuX8pht61A3Ifx2XFs7lf5pUjVIwoQ4IWPzNfIXItudrxDs/a9vhDFWJDNXkfk0UcpHraKxWi2pXKqv48uGyXsayIgAAwDsIdleAvHyH7v/gf1qz+7giw4L0zrD2auRHF3oCAADPYOpTgDMMQ49/slnJvx5WSJBVb97dllAHAECAItgFuBeSf9PctftktUivDG7lN+vsAAAAzyPYBbB3ftytV84ulju1fzMlNon1cYsAAICZCHYB6otfDmrS52dW1R7Xq75u71DDxy0CAABmI9gFoJU7jmrsvA0yDOnujjV1/7V1fd0kAADgBQS7ALP5wEnd99+fZc831KdZnJL6NmHBYAAArhAEuwCy+2im7pm9Rpm5+epUp6JeGNhCNtafAwDgikGwCxAnsnI1ZPYaHT2Vq8ZxUXr9rjbcMggAgCsMwS4AOByGxs7boD3HslS9fBm9PaydIsO4dRMAAFcagl0AeOXbHVq27YhCg6x6/a42qhIZ5usmAQAAHyDYlXLLt6VpxtLfJElT+zdVk6rFuzE7AAAIPAS7Umzf8Sw9eHZZk8Hta+gvbeN93SQAAOBDBLtSKtuer5Hvr9eJLLuaVy+npL6Nfd0kAADgYwS7Umry51u06cBJRYcH67U7WissmBmwAABc6Qh2pdCHP+/TB2v2yWKRXh7UStXLh/u6SQAAwA8Q7EqZzQdOauInmyVJY3vW1zX1K/u4RQAAwF8Q7EqRk1l2/f39dcrJc+jahlU0ujv3gAUAAOcQ7EoJh8PQg/P+p33HT6tGhXC9OKClrNwuDAAAnIdgV0r837JzixD/+87WKhfOnSUAAIA7gl0p8N1vR/TiNyxCDAAALoxgVwpMW5TCIsQAAOCiCHZ+Lj3brm2HMyRJD/Wu7+PWAAAAf0aw83Ob95+UYUjVy5dRpYhQXzcHAAD4MYKdn9u4/6QkqUX1aN82BAAA+D2fB7tXX31VCQkJCgsLU4cOHbRmzZoL7j9jxgw1aNBAZcqUUXx8vMaOHavs7Gwvtdb7Nu47IUlqEc+ECQAAcGE+DXbz5s3TuHHjlJSUpPXr16tFixZKTExUWlpaofvPmTNHjzzyiJKSkpSSkqJZs2Zp3rx5evTRR73ccu/5Zf8JSVJzKnYAAOAifBrsXnjhBY0YMUJDhw5V48aNNXPmTIWHh+utt94qdP8ff/xRnTt31u23366EhAT17t1bgwcPvmiVr7RKS8/WwZPZslqkZtWo2AEAgAsL8tWJc3NztW7dOk2YMMG1zWq1qmfPnlq1alWhx3Tq1Envvfee1qxZo/bt2+v333/XokWLdNdddxV5npycHOXk5Liep6enS5LsdrvsdruHPk1Bzve+nHOs331MklSnclmFWA1T2xuIPNEHuHz0g3+gH3yPPvAPpbEfStJWnwW7o0ePKj8/XzExMW7bY2JitHXr1kKPuf3223X06FFdffXVMgxDeXl5+tvf/nbBodhp06Zp8uTJBbYvWbJE4eHhl/chiiE5OfmSj/1yr1WSVRWMDC1atMhzjbrCXE4fwHPoB/9AP/gefeAfSlM/ZGVlFXtfnwW7S7F8+XI9/fTTeu2119ShQwft2LFDY8aM0ZNPPqmJEycWesyECRM0btw41/P09HTFx8erd+/eioqKMq2tdrtdycnJ6tWrl4KDL+32X/PfWSfpmG64qoluaM/CxCXliT7A5aMf/AP94Hv0gX8ojf3gHG0sDp8Fu0qVKslms+nw4cNu2w8fPqzY2NhCj5k4caLuuusuDR8+XJLUrFkzZWZm6r777tNjjz0mq7XgJYOhoaEKDS24/ltwcLBXOvRSz2MYhjYdONORrWtWLDU/fP7IW32NC6Mf/AP94Hv0gX8oTf1Qknb6bPJESEiI2rRpo6VLl7q2ORwOLV26VB07diz0mKysrALhzWazSToThALJnmNZOnnarpAgqxrERvq6OQAAoBTw6VDsuHHjNGTIELVt21bt27fXjBkzlJmZqaFDh0qS7r77blWrVk3Tpk2TJPXt21cvvPCCWrVq5RqKnThxovr27esKeIFi49llThrHRSkkyOfLDQIAgFLAp8Fu4MCBOnLkiJ544gkdOnRILVu21OLFi10TKvbu3etWoXv88cdlsVj0+OOP68CBA6pcubL69u2rp556ylcfwTQb952540TL+GjfNgQAAJQaPp88MXr0aI0ePbrQ15YvX+72PCgoSElJSUpKSvJCy3xro2thYtavAwAAxcMYnx+y5zu05eDZe8RSsQMAAMVEsPNDvx3OULbdociwINWqWNbXzQEAAKUEwc4P/bL/TLWuefVyslotPm4NAAAoLQh2fmjjvhOSpBbVo33aDgAAULoQ7PzQhrPBrjnBDgAAlADBzs9k5eZpe9opSSx1AgAASoZg52e2HExXvsNQTFSoYsuF+bo5AACgFCHY+ZmNDMMCAIBLRLDzMxv3c8cJAABwaQh2fuZcxY47TgAAgJIh2PmRPzJztfd4liSpebVo3zYGAACUOgQ7P+K8P2ytSmVVLjzYt40BAAClDsHOjzjvONGCYVgAAHAJCHZ+xHXHCSZOAACAS0Cw8xOGYbiGYlnqBAAAXAqCnZ84eDJbR0/lKshqUZOqUb5uDgAAKIUIdn7COQzbIDZSYcE23zYGAACUSgQ7P+EchuX6OgAAcKkIdn7CNXGCGbEAAOASEez8QL7D0CbnUidU7AAAwCUi2PmB34+cUmZuvsJDbKpXJdLXzQEAAKUUwc4PbDg7DNu0ajnZrBbfNgYAAJRaBDs/4LrjRDzX1wEAgEtHsPMDLEwMAAA8gWDnYzl5+UpJTZcktWTiBAAAuAwEOx9LSc2QPd9QhbIhql6+jK+bAwAASjGCnY85169rXr2cLBYmTgAAgEtHsPMx1x0nuL4OAABcJoKdj7nuOMGMWAAAcJkIdj6Unm3X70czJTEjFgAAXD6CnQ9t3n9ShiFViy6jShGhvm4OAAAo5Qh2PrTh7PV1LHMCAAA8gWDnQ3uOZkmSGsRyf1gAAHD5CHY+lJ2XL0kKD7H5uCUAACAQEOx8KNt+JtiFBhPsAADA5SPY+VBOnkOSFBZENwAAgMtHovAhZ8UujIodAADwAIKdD2Xbz1TsQqnYAQAADyBR+JBrKJaKHQAA8ACCnQ/lMBQLAAA8iGDnQ86KHUOxAADAE0gUPsTkCQAA4EkEOx86F+zoBgAAcPlIFD50biiWih0AALh8BDsfyct3KM9hSKJiBwAAPINE4SPZZ6t1EtfYAQAAzyDY+YhzqRNJCrHRDQAA4PKRKHzEWbELCbLKarX4uDUAACAQEOx8xDUjljXsAACAh5AqfCTHeZ9Yrq8DAAAeQrDzkew81rADAACeRarwkXNDsVTsAACAZxDsfMS1ODEVOwAA4CGkCh/JoWIHAAA8jGDnI9lnJ0+wODEAAPAUgp2P5JydPBHKcicAAMBDSBU+QsUOAAB4GsHOR5yzYpk8AQAAPIVU4SOuWbFMngAAAB5CsPMR1zp2VOwAAICH+EWqePXVV5WQkKCwsDB16NBBa9asKXLfbt26yWKxFHj06dPHiy2+fM5r7KjYAQAAT/F5sJs3b57GjRunpKQkrV+/Xi1atFBiYqLS0tIK3X/hwoVKTU11PTZv3iybzaa//OUvXm755cnhlmIAAMDDfJ4qXnjhBY0YMUJDhw5V48aNNXPmTIWHh+utt94qdP8KFSooNjbW9UhOTlZ4eHipC3bMigUAAJ7m02CXm5urdevWqWfPnq5tVqtVPXv21KpVq4r1HrNmzdKgQYNUtmxZs5ppimzWsQMAAB4W5MuTHz16VPn5+YqJiXHbHhMTo61bt170+DVr1mjz5s2aNWtWkfvk5OQoJyfH9Tw9PV2SZLfbZbfbL7HlF+d876LOkZ2bJ0kKtha9Dy7PxfoA3kE/+Af6wffoA/9QGvuhJG31abC7XLNmzVKzZs3Uvn37IveZNm2aJk+eXGD7kiVLFB4ebmbzJEnJycmFbt+fapVk1dYtm7Qo7RfT23ElK6oP4F30g3+gH3yPPvAPpakfsrKyir2vT4NdpUqVZLPZdPjwYbfthw8fVmxs7AWPzczM1Ny5czVlypQL7jdhwgSNGzfO9Tw9PV3x8fHq3bu3oqKiLr3xF2G325WcnKxevXopODi4wOvvHlwjnTyh9m1a6fqmF/6suDQX6wN4B/3gH+gH36MP/ENp7AfnaGNx+DTYhYSEqE2bNlq6dKn69+8vSXI4HFq6dKlGjx59wWPnz5+vnJwc3XnnnRfcLzQ0VKGhoQW2BwcHe6VDizpPbr4hSYooE1JqfrBKK2/1NS6MfvAP9IPv0Qf+oTT1Q0na6fOh2HHjxmnIkCFq27at2rdvrxkzZigzM1NDhw6VJN19992qVq2apk2b5nbcrFmz1L9/f1WsWNEXzb5srgWKWccOAAB4iM+D3cCBA3XkyBE98cQTOnTokFq2bKnFixe7JlTs3btXVqv7zNFt27bphx9+0JIlS3zRZI9w3VKMdewAAICH+DzYSdLo0aOLHHpdvnx5gW0NGjSQYRgmt8pczoodd54AAACeQrnIR1igGAAAeBrBzkdyWKAYAAB4GKnCBwzDoGIHAAA8jmDnA86JE5IUxuQJAADgIaQKHzg/2DF5AgAAeArBzgdyzs6ItVqkYJvFx60BAACBgmDnA+dfX2exEOwAAIBnEOx8gBmxAADADCQLH2BGLAAAMAPBzgeyz1bsCHYAAMCTCHY+kHO2YsdQLAAA8CSShQ+47hNLxQ4AAHgQwc4HXEOxVOwAAIAHkSx8wDUUS8UOAAB4EMHOB6jYAQAAM5AsfCCbih0AADABwc4HcqjYAQAAE5AsfIAFigEAgBkIdj6QY+eWYgAAwPNIFj6Qk0fFDgAAeB7BzgecCxSHBfP1AwAAzyFZ+IDrzhNBVOwAAIDnEOx84NxQLF8/AADwHJKFD3CvWAAAYAaCnQ84K3bMigUAAJ5EsvCBc5MnqNgBAADPIdj5AAsUAwAAMxDsfMB5SzGGYgEAgCeRLHyAih0AADADwc4HnBU7ljsBAACeRLLwgRy7c1YsFTsAAOA5BDsfyKZiBwAATECy8LJ8hyF7viFJCqNiBwAAPIhg52XO6+skKZSKHQAA8CCShZc5Z8RKVOwAAIBnEey8zHnXiRCbVVarxcetAQAAgYRg52XcJxYAAJiFdOFlzopdKIsTAwAADyPYeZkz2LHUCQAA8LRLShcrVqzQnXfeqY4dO+rAgQOSpHfffVc//PCDRxsXiBiKBQAAZilxuvjoo4+UmJioMmXK6H//+59ycnIkSSdPntTTTz/t8QYGmnMVO4ZiAQCAZ5U42E2dOlUzZ87UG2+8oeDgYNf2zp07a/369R5tXCDKtlOxAwAA5ihxuti2bZuuueaaAtvLlSunEydOeKJNAS0nj4odAAAwR4mDXWxsrHbs2FFg+w8//KDatWt7pFGBLOdsxY5gBwAAPK3EwW7EiBEaM2aMVq9eLYvFooMHD+r999/X+PHj9fe//92MNgaU7LMVO4ZiAQCApwWV9IBHHnlEDodDPXr0UFZWlq655hqFhoZq/Pjxuv/++81oY0ChYgcAAMxSomCXn5+vlStXatSoUXr44Ye1Y8cOnTp1So0bN1ZERIRZbQworGMHAADMUqJgZ7PZ1Lt3b6WkpCg6OlqNGzc2q10B69xQLBU7AADgWSUuGzVt2lS///67GW25IjiHYkOp2AEAAA+7pHXsxo8fry+++EKpqalKT093e+DCnBW7MCp2AADAw0o8eeKGG26QJPXr108Wi8W13TAMWSwW5efne651AYiKHQAAMEuJg92yZcvMaMcVI/vsvWKp2AEAAE8rcbDr2rWrGe24YnCvWAAAYJYSBztJOnHihGbNmqWUlBRJUpMmTTRs2DCVK1fOo40LRDl53CsWAACYo8Tp4ueff1adOnX04osv6vjx4zp+/LheeOEF1alTR+vXrzejjQGFih0AADBLiSt2Y8eOVb9+/fTGG28oKOjM4Xl5eRo+fLgefPBBff/99x5vZCDJYYFiAABgkhIHu59//tkt1ElSUFCQ/vGPf6ht27YebVwgOjcUS8UOAAB4VonLRlFRUdq7d2+B7fv27VNkZKRHGhXIuKUYAAAwS4nTxcCBA3Xvvfdq3rx52rdvn/bt26e5c+dq+PDhGjx4sBltDCjZZ9ex4xo7AADgaSUein3uuedksVh09913Ky8vT5IUHBysv//973rmmWc83sBAk+O6VywVOwAA4FklDnYhISF66aWXNG3aNO3cuVOSVKdOHYWHh3u8cYGIih0AADBLictGJ0+e1PHjxxUeHq5mzZqpWbNmCg8P1/Hjxy/pXrGvvvqqEhISFBYWpg4dOmjNmjUX3P/EiRMaNWqU4uLiFBoaqvr162vRokUlPq8vGIbhulcstxQDAACeVuJ0MWjQIM2dO7fA9g8//FCDBg0q0XvNmzdP48aNU1JSktavX68WLVooMTFRaWlphe6fm5urXr16affu3VqwYIG2bdumN954Q9WqVSvpx/AJe74hwzjz/8yKBQAAnlbiYLd69Wp17969wPZu3bpp9erVJXqvF154QSNGjNDQoUPVuHFjzZw5U+Hh4XrrrbcK3f+tt97S8ePH9cknn6hz585KSEhQ165d1aJFi5J+DJ9wVuskZsUCAADPK/E1djk5Oa5JE+ez2+06ffp0sd8nNzdX69at04QJE1zbrFarevbsqVWrVhV6zGeffaaOHTtq1KhR+vTTT1W5cmXdfvvt+uc//ymbrfAKWE5OjnJyclzPncPFdrtddru92O0tKed7n3+OU1ln2mGxSBZHvuxnr7eDOQrrA3gf/eAf6Affow/8Q2nsh5K0tcTBrn379vrPf/6jV155xW37zJkz1aZNm2K/z9GjR5Wfn6+YmBi37TExMdq6dWuhx/z+++/69ttvdccdd2jRokXasWOHRo4cKbvdrqSkpEKPmTZtmiZPnlxg+5IlS7wy4SM5Odn1/8eyJSlIQRZDX331lennxhnn9wF8h37wD/SD79EH/qE09UNWVlax9y1xsJs6dap69uypjRs3qkePHpKkpUuXau3atVqyZElJ365EHA6HqlSpov/85z+y2Wxq06aNDhw4oOnTpxcZ7CZMmKBx48a5nqenpys+Pl69e/dWVFSUaW212+1KTk5Wr169FBwcLEnakXZK+t+PKhsaohtuKDicDc8qrA/gffSDf6AffI8+8A+lsR9KMjm1xMGuc+fOWrVqlaZPn64PP/xQZcqUUfPmzTVr1izVq1ev2O9TqVIl2Ww2HT582G374cOHFRsbW+gxcXFxCg4Odht2bdSokQ4dOqTc3FyFhIQUOCY0NFShoaEFtgcHB3ulQ88/T/7ZSxpDg62l5ocpEHirr3Fh9IN/oB98jz7wD6WpH0rSzhIHO0lq2bKl3n///Us51CUkJERt2rTR0qVL1b9/f0lnKnJLly7V6NGjCz2mc+fOmjNnjhwOh6zWMyHpt99+U1xcXKGhzt84FydmDTsAAGCGEk/NXL9+vTZt2uR6/umnn6p///569NFHlZubW6L3GjdunN544w298847SklJ0d///ndlZmZq6NChkqS7777bbXLF3//+dx0/flxjxozRb7/9pi+//FJPP/20Ro0aVdKP4ROuxYlZ6gQAAJigxMHur3/9q3777TdJZyYzDBw4UOHh4Zo/f77+8Y9/lOi9Bg4cqOeee05PPPGEWrZsqQ0bNmjx4sWuCRV79+5Vamqqa//4+Hh9/fXXWrt2rZo3b64HHnhAY8aM0SOPPFLSj+ET2XYWJwYAAOYp8VDsb7/9ppYtW0qS5s+fr65du2rOnDlauXKlBg0apBkzZpTo/UaPHl3k0Ovy5csLbOvYsaN++umnErbaP+TkUbEDAADmKXHpyDAMORxnAso333yjG264QdKZatrRo0c927oAQ8UOAACYqcQJo23btpo6dareffddfffdd+rTp48kadeuXQXWpIM75zV23E4MAACYocTBbsaMGVq/fr1Gjx6txx57THXr1pUkLViwQJ06dfJ4AwPJuVmxVOwAAIDnlfgau+bNm7vNinWaPn16kbf1whmuWbEsdwIAAExwSevYFSYsLMxTbxWwXNfYBVGxAwAAnkfC8CLXrFgqdgAAwAQEOy9yVuy4xg4AAJiBhOFFzoods2IBAIAZCHZelEPFDgAAmMhjCWPfvn0aNmyYp94uIGW7ljuhYgcAADzPY8Hu+PHjeueddzz1dgEpx7VAMRU7AADgecVe7uSzzz674Ou///77ZTcm0FGxAwAAZip2sOvfv78sFosMwyhyH4vF4pFGBSpuKQYAAMxU7DHBuLg4LVy4UA6Ho9DH+vXrzWxnQHDeUiyUyRMAAMAExU4Ybdq00bp164p8/WLVPJx3SzEqdgAAwATFHop9+OGHlZmZWeTrdevW1bJlyzzSqEDFAsUAAMBMxQp2v/zyizp37iyrtehAUrZsWXXt2tVjDQtELFAMAADMVKzSUatWrXT06FFJUu3atXXs2DFTGxWoqNgBAAAzFSthREdHa9euXZKk3bt3y+FwmNqoQOVcx47lTgAAgBmKNRR76623qmvXroqLi5PFYlHbtm1lsxUeTljPrnAOh6HcfBYoBgAA5ilWsPvPf/6jW265RTt27NADDzygESNGKDIy0uy2BRTn9XUSFTsAAGCOYs+Kve666yRJ69at05gxYwh2JeS8vk6iYgcAAMxR7GDnNHv2bDPaEfCcFbsgq0VBNoIdAADwPBKGl5ybEcswLAAAMAfBzkuynbcTYxgWAACYhJThJSx1AgAAzEaw8xLnUGwoixMDAACTkDK8JJvbiQEAAJMR7Lwkh9uJAQAAk5EyvMRZsQujYgcAAExCsPMSrrEDAABmI2V4SQ4VOwAAYDKCnZdwjR0AADAbKcNLcpgVCwAATEaw85JsKnYAAMBkpAwv4V6xAADAbAQ7Lzk3FMtXDgAAzEHK8JJzy51QsQMAAOYg2HlJtv3scicEOwAAYBKCnZfk5J2t2DEUCwAATELK8BIqdgAAwGwEOy9huRMAAGA2UoaXsEAxAAAwG8HOS6jYAQAAs5EyvMRZseMaOwAAYBaCnZfk2JkVCwAAzEXK8JJsKnYAAMBkBDsvyaZiBwAATEbK8BKusQMAAGYj2HmBPd+hfIchSQpjuRMAAGASgp0XOIdhJSmU5U4AAIBJSBle4ByGlbjGDgAAmIeU4QXnT5ywWCw+bg0AAAhUBDsvyLY7byfG1w0AAMxD0vCCnDzn7cSYOAEAAMxDsPMCZ8WOYAcAAMxEsPMCbicGAAC8gaThBSxODAAAvIFg5wXOWbFhrGEHAABMRNLwguw851AsFTsAAGAegp0X5LgmT/B1AwAA8/hF0nj11VeVkJCgsLAwdejQQWvWrCly37ffflsWi8XtERYW5sXWlpxrgWKusQMAACbyebCbN2+exo0bp6SkJK1fv14tWrRQYmKi0tLSijwmKipKqamprseePXu82OKSc06eYFYsAAAwk8+TxgsvvKARI0Zo6NChaty4sWbOnKnw8HC99dZbRR5jsVgUGxvresTExHixxSXHOnYAAMAbgnx58tzcXK1bt04TJkxwbbNarerZs6dWrVpV5HGnTp1SzZo15XA41Lp1az399NNq0qRJofvm5OQoJyfH9Tw9PV2SZLfbZbfbPfRJCnK+t91uV1bOmf8PscrUc8Ld+X0A36Ef/AP94Hv0gX8ojf1Qkrb6NNgdPXpU+fn5BSpuMTEx2rp1a6HHNGjQQG+99ZaaN2+ukydP6rnnnlOnTp20ZcsWVa9evcD+06ZN0+TJkwtsX7JkicLDwz3zQS4gOTlZW3dbJVm1f89uLVr0u+nnhLvk5GRfNwGiH/wF/eB79IF/KE39kJWVVex9fRrsLkXHjh3VsWNH1/NOnTqpUaNGev311/Xkk08W2H/ChAkaN26c63l6erri4+PVu3dvRUVFmdZOu92u5ORk9erVS6u+2i6l7lfjhvV0Q/c6pp0T7s7vg+DgYF8354pFP/gH+sH36AP/UBr7wTnaWBw+DXaVKlWSzWbT4cOH3bYfPnxYsbGxxXqP4OBgtWrVSjt27Cj09dDQUIWGhhZ6nDc6NDg4WLn5hiSpbKh3zgl33uprXBj94B/oB9+jD/xDaeqHkrTTp5MnQkJC1KZNGy1dutS1zeFwaOnSpW5VuQvJz8/Xpk2bFBcXZ1YzLxuzYgEAgDf4fCh23LhxGjJkiNq2bav27dtrxowZyszM1NChQyVJd999t6pVq6Zp06ZJkqZMmaKrrrpKdevW1YkTJzR9+nTt2bNHw4cP9+XHuKAc1y3FmBULAADM4/NgN3DgQB05ckRPPPGEDh06pJYtW2rx4sWuCRV79+6V1Xqu0vXHH39oxIgROnTokMqXL682bdroxx9/VOPGjX31ES6K5U4AAIA3+DzYSdLo0aM1evToQl9bvny52/MXX3xRL774ohda5Tk5rnvFMhQLAADMQ9LwAip2AADAGwh2XuC6VywVOwAAYCKShhe4ZsVSsQMAACYi2HlBtmtWLF83AAAwD0nDC84NxVKxAwAA5iHYeYFzKJaKHQAAMBNJw2SGYZwX7KjYAQAA8xDsTOYMdRKzYgEAgLlIGiY7P9hRsQMAAGYi2JnMOXHCZrUo2MbXDQAAzEPSMFm2cw07hmEBAIDJSBsmy+V2YgAAwEsIdibLzju7ODEVOwAAYDLShsmy7dxODAAAeAfBzmQ5XGMHAAC8hLRhshzXfWKp2AEAAHMR7ExGxQ4AAHgLacNkrskTVOwAAIDJCHYmy3Ytd8JXDQAAzEXaMNm5oVgqdgAAwFwEO5OdmzzBVw0AAMxF2jCZ85ZiXGMHAADMRrAzGbNiAQCAt5A2TMY6dgAAwFsIdiZjKBYAAHgLwc5kOXaGYgEAgHeQNkzmXKA4lIodAAAwGcHOZFTsAACAt5A2TJbDLcUAAICXEOxM5po8QcUOAACYjLRhMue9YrnGDgAAmI1gZ7Jc51AsFTsAAGAy0obJnBU7rrEDAABmI9iZ7NxyJ3zVAADAXKQNk+W4Jk9QsQMAAOYi2Jksh6FYAADgJQQ7E+UbUp7DkMQCxQAAwHykDROdHYWVRMUOAACYj2BnIvt5wY6KHQAAMBtpw0S5Z4NdiM0qq9Xi28YAAICAR7AzkXMolqVOAACAN5A4TOQciuX6OgAA4A0EOxM5gx3X1wEAAG8gcZjI7jhzXR0VOwAA4A0EOxOdG4rlawYAAOYjcZjo3FAsFTsAAGA+gp2JqNgBAABvInGYyBXsqNgBAAAvINiZKO/MbWJZxw4AAHgFicNEVOwAAIA3EexM5Jo8wXInAADACwh2JnKuY8cCxQAAwBtIHCbilmIAAMCbCHYm4pZiAADAm0gcJqJiBwAAvIlgZyIWKAYAAN5E4jARtxQDAADeRLAzUR4VOwAA4EUkDhM5lzvhGjsAAOANBDsT5TIrFgAAeBGJw0R5zIoFAABe5BfB7tVXX1VCQoLCwsLUoUMHrVmzpljHzZ07VxaLRf379ze3gZeIWbEAAMCbfJ445s2bp3HjxikpKUnr169XixYtlJiYqLS0tAset3v3bo0fP15dunTxUktLjlmxAADAm3we7F544QWNGDFCQ4cOVePGjTVz5kyFh4frrbfeKvKY/Px83XHHHZo8ebJq167txdaWjN04818qdgAAwBuCfHny3NxcrVu3ThMmTHBts1qt6tmzp1atWlXkcVOmTFGVKlV07733asWKFRc8R05OjnJyclzP09PTJUl2u112u/0yP0HR7Ha7q2Jnk2HquVA453fOd+9b9IN/oB98jz7wD6WxH0rSVp8Gu6NHjyo/P18xMTFu22NiYrR169ZCj/nhhx80a9YsbdiwoVjnmDZtmiZPnlxg+5IlSxQeHl7iNheXYUh2x5mv94fvlikqxLRT4SKSk5N93QSIfvAX9IPv0Qf+oTT1Q1ZWVrH39WmwK6mMjAzdddddeuONN1SpUqViHTNhwgSNGzfO9Tw9PV3x8fHq3bu3oqKizGqqMk/nSD99J0nqc10vRYYFm3YuFM5utys5OVm9evVScDDfv6/QD/6BfvA9+sA/lMZ+cI42FodPg12lSpVks9l0+PBht+2HDx9WbGxsgf137typ3bt3q2/fvq5tDseZ8c6goCBt27ZNderUcTsmNDRUoaGhBd4rODjY1A7NP32ubBpRJkzBrGXnM2b3NYqHfvAP9IPv0Qf+oTT1Q0na6dO0ERISojZt2mjp0qWubQ6HQ0uXLlXHjh0L7N+wYUNt2rRJGzZscD369eun7t27a8OGDYqPj/dm8y8o++widhaLFGyz+Lg1AADgSuDzodhx48ZpyJAhatu2rdq3b68ZM2YoMzNTQ4cOlSTdfffdqlatmqZNm6awsDA1bdrU7fjo6GhJKrDd13Ly8iVJYUFWWSwEOwAAYD6fB7uBAwfqyJEjeuKJJ3To0CG1bNlSixcvdk2o2Lt3r6zW0jeMmX12Six3nQAAAN7i82AnSaNHj9bo0aMLfW358uUXPPbtt9/2fIM8IPfsUGwI19YBAAAvIXWYJNvuHIqlYgcAALyDYGcS5+QJ7joBAAC8hdRhkpyzwS6UoVgAAOAlpA6T5Jwdig1l8gQAAPASgp1JXLNiqdgBAAAvIXWYhKFYAADgbaQOk2TnMRQLAAC8i2Bnkhw7FTsAAOBdpA6TuG4pxnInAADAS0gdJjk3eYKhWAAA4B0EO5NkM3kCAAB4GanDJLlMngAAAF5GsDOJayiWa+wAAICXkDpMku288wRDsQAAwEtIHSY5t0AxQ7EAAMA7CHYmcQY7hmIBAIC3kDpMwlAsAADwNlKHSc5V7BiKBQAA3kGwM0k2txQDAABeRuowifOWYgQ7AADgLUG+bkCgYigWAAKTYRjKy8tTfn5+iY6z2+0KCgpSdnZ2iY+F5/hjP9hsNgUFBclisVz2exHsTMICxQAQeHJzc5WamqqsrKwSH2sYhmJjY7Vv3z6P/AWOS+Ov/RAeHq64uDiFhIRc1vsQ7ExybiiWih0ABAKHw6Fdu3bJZrOpatWqCgkJKVEwcDgcOnXqlCIiImS18o9+X/G3fjAMQ7m5uTpy5Ih27dqlevXqXVa7CHYmyHcYsucbkrjGDgACRW5urhwOh+Lj4xUeHl7i4x0Oh3JzcxUWFuYXgeJK5Y/9UKZMGQUHB2vPnj2utl0q//hEAcZZrZMYigWAQOMvYQCBxVM/V/x0msB5fZ3EUCwAAPAegp0JnBU7m8WQzeo/F2YCAIDARrAzgbNixygsAADuJk2apJiYGFksFn3yySe+bk7AIXqYwFmxY94EAMDX7rnnHlksFtejYsWKuu666/TLL7947ByTJk1Sy5YtL7pfSkqKJk+erNdff12pqam6/vrrtWXLFt16661KSEiQxWLRjBkzPNauX375RV26dFFYWJji4+P17LPPXvSYtWvXqkePHoqOjlb58uWVmJiojRs3ul7fvXu32/fpfPz0009u7zNjxgw1aNBAZcqUUXx8vMaOHavs7GyPfbaiED1M4KzYhfDtAgD+JN+Rr+W7l+uDTR9o+e7lyneYv0juddddp9TUVKWmpmrp0qUKCgrSjTfeaPp5/2znzp2SpJtuukmxsbEKDQ1VVlaWateurWeeeUaxsbEeO1d6erp69+6tmjVrat26dZo+fbomTZqk//znP0Uec+rUKV133XWqUaOGVq9erR9++EGRkZFKTEyU3W532/ebb75xfaepqalq06aN67U5c+bokUceUVJSklJSUjRr1izNmzdPjz76qMc+X1GIHibItp/5JWUoFgBwvs93fK7aL9dW93e66/aFt6v7O92V8FKCFqYsNPW8oaGhio2NVWxsrFq2bKlHHnlE+/bt05EjR1z77Nu3TwMGDFB0dLQqVKigm266Sbt373a9vnz5crVv315ly5ZVdHS0OnfurD179ujtt9/W5MmTtXHjRlf16u233y7QhkmTJqlv376SzswAda4B2K5dO02fPl2DBg1SaGioxz7z+++/r9zcXL311ltq0qSJBg0apAceeOCCFcGtW7fq+PHjmjJliho0aKAmTZooKSlJhw8f1p49e9z2rVixous7jY2NVXBwsOu1H3/8UZ07d9btt9+uhIQE9e7dW4MHD9aaNWs89vmKQvQwgfN2YkHMmwAAnLUwZaGGfDlE+zP2u20/kH5At314m+nhzunUqVN67733VLduXVWsWFHSmdtsJSYmKjIyUitWrNDKlSsVERGh6667Trm5ucrLy1P//v3VtWtX/fLLL1q1apXuu+8+WSwWDRw4UA899JCaNGniql4NHDiwwHnHjx+v2bNnS5Jrv8tRVIB0WrVqla655hq3OzkkJiZq27ZtOnHiRKHHNGjQQBUrVtSsWbOUm5ur06dPa9asWWrUqJESEhLc9u3Xr5+qVKmiq6++Wp999pnba506ddK6detcQe7333/XokWLdMMNN1zSZy0JFig2ARU7AMD58h35Gvv1WBkyCrxmyJBFFj24+EHd1OAm2ayeXybriy++UEREhCQpMzNTcXFx+uKLL1xrp82bN08Oh0Nvvvmmq5I2e/ZsRUdHa/ny5Wrbtq1OnjypG2+8UXXq1JEkNWrUyPX+ERERCgoKuuBQakREhKKjoyXJI0OuDRo0ULly5Yp8/dChQ6pVq5bbtpiYGEnS4cOHVaNGjQLHREZGavny5erfv7+efPJJSVK9evX09ddfKygoyPU5nn/+eXXu3FlWq1UfffSR+vfvr08++UT9+vWTJN1+++06evSorr76ate9hf/2t78xFFtanQt2BX+BAQBXnhV7VxSo1J3PkKF96fu0Yu8KU87fvXt3bdiwQRs2bNCaNWuUmJio66+/3jW8uHHjRu3YsUORkZGKiIhQRESEKlSooOzsbO3cuVMVKlTQPffco8TERPXt21cvvfTSZVfcLtfWrVt18803e/Q9T58+rXvvvVedO3fWTz/9pJUrV6pp06bq06ePTp8+LUmqVKmSxo0bpw4dOqhdu3Z65plndOedd2r69Omu91m+fLmefvppvfbaa1q/fr0WLlyoL7/80hUWzUTFzgTOoVgqdgAASUrNKF4IKu5+JVW2bFnVrVvX9fzNN99UuXLl9MYbb2jq1Kk6deqU2rRpo/fff7/AsZUrV5Z0poL3wAMPaPHixZo3b54ef/xxJScn66qrrjKlzZcrNjZWhw8fdtvmfO6s3P3ZnDlztHv3bq1atcpVzZwzZ47Kly+vTz/9VIMGDSr0uA4dOig5Odn1fOLEibrrrrs0fPhwSVKzZs2UmZmp++67T4899pipdy8hepiga/3KemtIa10X77j4zgCAgBcXGefR/S6XxWKR1Wp1VaFat26t7du3q0qVKqpbt67b4/zhzlatWmnChAn68ccf1bRpU82ZM0eSFBISovx882f3lkTHjh31/fffu81mTU5OVoMGDVxDwn+WlZXlNrFDOjfRw+Eo+u/0DRs2KC7uXN853+d8NtuZIXbDMHc0j2BngpioMHWpW0k1I3zdEgCAP+hSo4uqR1aXRYXPqrPIovioeHWp0cWU8+fk5OjQoUM6dOiQUlJSdP/99+vUqVOuWap33HGHKlWqpJtuukkrVqzQrl27tHz5cj3wwAPav3+/du3apQkTJmjVqlXas2ePlixZou3bt7uus0tISNCuXbu0YcMGHT16VDk5OcVuW25urmuYODc3VwcOHNCGDRu0Y8eOCx7XsGFDffzxx0W+fvvttyskJET33nuvtmzZonnz5umll17Sgw8+6Nrn448/VsOGDV3Pe/XqpT/++EOjRo1SSkqKtmzZoqFDhyooKEjdu3eXJL3zzjv64IMPtHXrVm3dulVPP/203nrrLd1///2u9+nbt6/+/e9/a+7cudq1a5eSk5M1ceJE9e3b1xXwzMJQLAAAJrNZbXox8UUNWDBAFlncJlE4w96M62aYMnFCkhYvXuyqKEVGRqphw4aaP3++unXrJkkKDw/X999/r3/+85+65ZZblJGRoWrVqqlHjx6KiorS6dOntXXrVr3zzjs6duyY4uLiNGrUKP31r3+VJN16661auHChunfvrhMnTmj27Nm65557itW2gwcPqlWrVq7nzz33nJ577jl17dpVy5cvL/K4bdu26eTJk0W+Xq5cOS1ZskSjRo1SmzZtVKlSJT3xxBO67777lJ6eLkk6efKktm3b5jqmYcOG+vzzzzV58mR17NhRVqtVrVq1cvv+JOnJJ5/Unj17FBQUpIYNG2revHm67bbbXK8//vjjslgsevzxx3XgwAFVrlxZffv21VNPPVWs7+RyWAyza4J+Jj09XeXKldPJkycVFRVl2nnsdrtravP5a9vAe+gD/0A/+Af64fJlZ2dr165dqlWrlsLCwkp8vMPh0Pvr39ej3z/qNpEiPipeM66boVsa3eLJ5qIIDodD6enpioqKMvVat5K60M9XSbILFTsAALykb92+GtRykFbuX6nUjFTFRcapS40uplXqcOUh2AEA4EU2q03dErr5uhkIUP5TgwQAAMBlIdgBAAAECIIdAAAlcIXNOYSXeOrnimAHAEAxOGcTZ2Vl+bglCETOn6vLnbXO5AkAAIrBZrMpOjpaaWlpks6s/Xb+HQouxuFwKDc3V9nZ2X61zMaVxt/6wTAMZWVlKS0tTdHR0Ze9gDHBDgCAYoqNjZUkV7grCcMwdPr0aZUpU6ZEgRCe5a/9EB0d7fr5uhwEOwAAislisSguLk5VqlRxuwdpcdjtdn3//fe65pprWCTah/yxH4KDgz12qzGCHQAAJWSz2Ur8F7HNZlNeXp7CwsL8JlBciQK9H3w/uAwAAACPINgBAAAECIIdAABAgLjirrFzLgCYnp5u6nnsdruysrKUnp4ekGP4pQF94B/oB/9AP/gefeAfSmM/ODNLcRYxvuKCXUZGhiQpPj7exy0BAAAovoyMDJUrV+6C+1iMK+zeKA6HQwcPHlRkZKSp69ekp6crPj5e+/btU1RUlGnnQdHoA/9AP/gH+sH36AP/UBr7wTAMZWRkqGrVqhddVPmKq9hZrVZVr17da+eLiooqNT84gYo+8A/0g3+gH3yPPvAPpa0fLlapc2LyBAAAQIAg2AEAAAQIgp1JQkNDlZSUpNDQUF835YpFH/gH+sE/0A++Rx/4h0Dvhytu8gQAAECgomIHAAAQIAh2AAAAAYJgBwAAECAIdgAAAAGCYGeCV199VQkJCQoLC1OHDh20Zs0aXzcpoH3//ffq27evqlatKovFok8++cTtdcMw9MQTTyguLk5lypRRz549tX37dt80NkBNmzZN7dq1U2RkpKpUqaL+/ftr27ZtbvtkZ2dr1KhRqlixoiIiInTrrbfq8OHDPmpxYPr3v/+t5s2buxZe7dixo7766ivX6/SB9z3zzDOyWCx68MEHXdvoB/NNmjRJFovF7dGwYUPX64HcBwQ7D5s3b57GjRunpKQkrV+/Xi1atFBiYqLS0tJ83bSAlZmZqRYtWujVV18t9PVnn31WL7/8smbOnKnVq1erbNmySkxMVHZ2tpdbGri+++47jRo1Sj/99JOSk5Nlt9vVu3dvZWZmuvYZO3asPv/8c82fP1/fffedDh48qFtuucWHrQ481atX1zPPPKN169bp559/1rXXXqubbrpJW7ZskUQfeNvatWv1+uuvq3nz5m7b6QfvaNKkiVJTU12PH374wfVaQPeBAY9q3769MWrUKNfz/Px8o2rVqsa0adN82KorhyTj448/dj13OBxGbGysMX36dNe2EydOGKGhocYHH3zggxZeGdLS0gxJxnfffWcYxpnvPDg42Jg/f75rn5SUFEOSsWrVKl8184pQvnx5480336QPvCwjI8OoV6+ekZycbHTt2tUYM2aMYRj8LnhLUlKS0aJFi0JfC/Q+oGLnQbm5uVq3bp169uzp2ma1WtWzZ0+tWrXKhy27cu3atUuHDh1y65Ny5cqpQ4cO9ImJTp48KUmqUKGCJGndunWy2+1u/dCwYUPVqFGDfjBJfn6+5s6dq8zMTHXs2JE+8LJRo0apT58+bt+3xO+CN23fvl1Vq1ZV7dq1dccdd2jv3r2SAr8PgnzdgEBy9OhR5efnKyYmxm17TEyMtm7d6qNWXdkOHTokSYX2ifM1eJbD4dCDDz6ozp07q2nTppLO9ENISIiio6Pd9qUfPG/Tpk3q2LGjsrOzFRERoY8//liNGzfWhg0b6AMvmTt3rtavX6+1a9cWeI3fBe/o0KGD3n77bTVo0ECpqamaPHmyunTpos2bNwd8HxDsAHjUqFGjtHnzZrfrWeA9DRo00IYNG3Ty5EktWLBAQ4YM0XfffefrZl0x9u3bpzFjxig5OVlhYWG+bs4V6/rrr3f9f/PmzdWhQwfVrFlTH374ocqUKePDlpmPoVgPqlSpkmw2W4GZNYcPH1ZsbKyPWnVlc37v9Il3jB49Wl988YWWLVum6tWru7bHxsYqNzdXJ06ccNuffvC8kJAQ1a1bV23atNG0adPUokULvfTSS/SBl6xbt05paWlq3bq1goKCFBQUpO+++04vv/yygoKCFBMTQz/4QHR0tOrXr68dO3YE/O8Cwc6DQkJC1KZNGy1dutS1zeFwaOnSperYsaMPW3blqlWrlmJjY936JD09XatXr6ZPPMgwDI0ePVoff/yxvv32W9WqVcvt9TZt2ig4ONitH7Zt26a9e/fSDyZzOBzKycmhD7ykR48e2rRpkzZs2OB6tG3bVnfccYfr/+kH7zt16pR27typuLi4gP9dYCjWw8aNG6chQ4aobdu2at++vWbMmKHMzEwNHTrU100LWKdOndKOHTtcz3ft2qUNGzaoQoUKqlGjhh588EFNnTpV9erVU61atTRx4kRVrVpV/fv3912jA8yoUaM0Z84cffrpp4qMjHRdp1KuXDmVKVNG5cqV07333qtx48apQoUKioqK0v3336+OHTvqqquu8nHrA8eECRN0/fXXq0aNGsrIyNCcOXO0fPlyff311/SBl0RGRrquLXUqW7asKlas6NpOP5hv/Pjx6tu3r2rWrKmDBw8qKSlJNptNgwcPDvzfBV9Pyw1Er7zyilGjRg0jJCTEaN++vfHTTz/5ukkBbdmyZYakAo8hQ4YYhnFmyZOJEycaMTExRmhoqNGjRw9j27Ztvm10gCns+5dkzJ4927XP6dOnjZEjRxrly5c3wsPDjZtvvtlITU31XaMD0LBhw4yaNWsaISEhRuXKlY0ePXoYS5Yscb1OH/jG+cudGAb94A0DBw404uLijJCQEKNatWrGwIEDjR07drheD+Q+sBiGYfgoUwIAAMCDuMYOAAAgQBDsAAAAAgTBDgAAIEAQ7AAAAAIEwQ4AACBAEOwAAAACBMEOAAAgQBDsAMCHli9fLovFUuC+lQBwKQh2AAAAAYJgBwAAECAIdgCuaA6HQ9OmTVOtWrVUpkwZtWjRQgsWLJB0bpj0yy+/VPPmzRUWFqarrrpKmzdvdnuPjz76SE2aNFFoaKgSEhL0/PPPu72ek5Ojf/7zn4qPj1doaKjq1q2rWbNmue2zbt06tW3bVuHh4erUqZO2bdtm7gcHEJAIdgCuaNOmTdN///tfzZw5U1u2bNHYsWN155136rvvvnPt8/DDD+v555/X2rVrVblyZfXt21d2u13SmUA2YMAADRo0SJs2bdKkSZM0ceJEvf32267j7777bn3wwQd6+eWXlZKSotdff10RERFu7Xjsscf0/PPP6+eff1ZQUJCGDRvmlc8PILBYDMMwfN0IAPCFnJwcVahQQd988406duzo2j58+HBlZWXpvvvuU/fu3TV37lwNHDhQknT8+HFVr15db7/9tgYMGKA77rhDR44c0ZIlS1zH/+Mf/9CXX36pLVu26LffflODBg2UnJysnj17FmjD8uXL1b17d33zzTfq0aOHJGnRokXq06ePTp8+rbCwMJO/BQCBhIodgCvWjh07lJWVpV69eikiIsL1+O9//6udO3e69js/9FWoUEENGjRQSkqKJCklJUWdO3d2e9/OnTtr+/btys/P14YNG2Sz2dS1a9cLtqV58+au/4+Li5MkpaWlXfZnBHBlCfJ1AwDAV06dOiVJ+vLLL1WtWjW310JDQ93C3aUqU6ZMsfYLDg52/b/FYpF05vo/ACgJKnYArliNGzdWaGio9u7dq7p167o94uPjXfv99NNPrv//448/9Ntvv6lRo0aSpEaNGmnlypVu77ty5UrVr19fNptNzZo1k8PhcLtmDwDMQsUOwBUrMjJS48eP19ixY+VwOHT11Vfr5MmTWrlypaKiolSzZk1J0pQpU1SxYkXFxMToscceU6VKldS/f39J0kMPPaR27drpySef1MCBA7Vq1Sr93//9n1577TVJUkJCgoYMGaJhw4bp5ZdfVosWLbRnzx6lpaVpwIABvvroAAIUwQ7AFe3JJ59U5cqVNW3aNP3++++Kjo5W69at9eijj7qGQp955hmNGTNG27dvV8uWLfX5558rJCREktS6dWt9+OGHeuKJJ/Tkk08qLi5OU6ZM0T333OM6x7///W89+uijGjlypI4dO6YaNWro0Ucf9cXHBRDgmBULAEVwzlj9448/FB0d7evmAMBFcY0dAABAgCDYAQAABAiGYgEAAAIEFTsAAIAAQbADAAAIEAQ7AACAAEGwAwAACBAEOwAAgABBsAMAAAgQBDsAAIAAQbADAAAIEAQ7AACAAPH/FT4RBYhsohcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# history = ([k.to('cpu').numpy() for k in history])\n",
    "plt.plot(history)\n",
    "plt.scatter(\n",
    "    [best_epoch], \n",
    "    best_f1.item(),\n",
    "    color = \"green\",\n",
    "    label = f\"Best f1 : {round(best_f1.item(),3)}\"\n",
    ")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.tight_layout()\n",
    "plt.title(\"SetFit training results- AG news - 10 shots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77f9d4970224cae9ff41db9082d3752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd274c3905241e785cf2299fadd74a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c589f15830a4db0af5e5b4daae1efb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e9565393b44e238544b645298f8583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/732 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a240b7c7a947d58b15adbe842088c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c779bc58c7411a82475b48746016e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29dcfeb94094fcfb471d6165044e0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54bbdfbbb7f047be813bfb4d37c3ded7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d31a9db32e14040abffe5bc60835f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ada7d3f21541439519ee40a71deade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162c103fd8c74f76a71835f28d84943f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e973e7bfefc4418989b6e589fba81b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer(\n",
    "    \"peulsilva/phrase-bert-setfit-10shots\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_n_shots_per_class(\n",
    "    train_text,\n",
    "    train_labels,\n",
    "    n_shots= n_shots,\n",
    "    num_classes= num_classes\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
