{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/Desktop/Polytechnique/few-shot-learning-transformers/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import LayoutLMForTokenClassification,\\\n",
    "    LayoutLMTokenizer, AdamW, LayoutLMv2Processor, LayoutLMv2ForTokenClassification\n",
    "# from tensordict import TensorDict\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import ImageDraw, Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import logging\n",
    "# from torchvision.transforms import PILToTensor\n",
    "from torcheval.metrics.functional import multiclass_f1_score, \\\n",
    "    multiclass_accuracy\n",
    "\n",
    "import os \n",
    "if 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "    \n",
    "from src.preprocessing.make_dataset import ImageLayoutDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import io\n",
    "import json\n",
    "\n",
    "import google.auth\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_basic():\n",
    "    \"\"\"Insert new file.\n",
    "    Returns : Id's of the file uploaded\n",
    "\n",
    "    Load pre-authorized user credentials from the environment.\n",
    "    TODO(developer) - See https://developers.google.com/identity\n",
    "    for guides on implementing OAuth2 for the application.\n",
    "    \"\"\"\n",
    "    creds, _ = google.auth.default()\n",
    "\n",
    "    try:\n",
    "        # create drive api client\n",
    "        service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "        file_metadata = {'name': 'download.jpeg'}\n",
    "        media = MediaFileUpload('download.jpeg',\n",
    "                                mimetype='image/jpeg')\n",
    "        # pylint: disable=maybe-no-member\n",
    "        file = service.files().create(body=file_metadata, media_body=media,\n",
    "                                      fields='id').execute()\n",
    "        print(F'File ID: {file.get(\"id\")}')\n",
    "\n",
    "    except HttpError as error:\n",
    "        print(F'An error occurred: {error}')\n",
    "        file = None\n",
    "\n",
    "    return file.get('id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=V7yU8EorhYdiwLZrrL1SAu6o4KJzQM&access_type=offline&code_challenge=xkV9JlHyerrTqnC7QMcA7ASPfx7iJqDj0JYx3_n971o&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Application default credentials (ADC) were updated.\n",
      "\n",
      "You are now logged in as [pedrolmssilva@gmail.com].\n",
      "Your current project is [None].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth login --enable-gdrive-access --update-adc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds, _ = google.auth.default(\n",
    "    scopes= [\"https://www.googleapis.com/auth/drive.file\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds.scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ID: 1y5hkcTQE5NlioxaPk2Lo9JqExBBMkjQD\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # create drive api client\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    file_metadata = {\n",
    "        'name': 'model.pt',\n",
    "        \"parents\": [\"1TW9wrG-7_1YTjbc8JaAJ2bYDESN3owdO\"]\n",
    "    }\n",
    "    media = MediaFileUpload('data/model.pt',\n",
    "                            mimetype='text/plain')\n",
    "    # pylint: disable=maybe-no-member\n",
    "    file = service\\\n",
    "        .files().\\\n",
    "        create(\n",
    "            body=file_metadata, \n",
    "            media_body=media,\n",
    "            fields='id'\n",
    "        ).execute()\n",
    "    print(F'File ID: {file.get(\"id\")}')\n",
    "\n",
    "except HttpError as error:\n",
    "    print(F'An error occurred: {error}')\n",
    "    file = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:\n",
      "model.pt (1y5hkcTQE5NlioxaPk2Lo9JqExBBMkjQD)\n",
      "Untitled0.ipynb (1jCXO4ci1ycC0ZELjm7xnbK1WPb-164EL)\n",
      "X forum eleves contact (1MVZSYrWOh0-2_-ZGiSgLXnE3PrGVjKHbogk8mICRFXM)\n",
      "Jeudi 05/09 (1CWibnlKRNzWxjxuDKehLSgekQFgLJyDRT0k35C2vjv4)\n",
      "models (175HZ7NCBjMBQ6pyo8zpMNYizrGFIUbQ9)\n",
      "train.log (1jCr9Z1OJnbMG8_29SXsJJE82gbo70Ns2)\n",
      "train.log (14dIeRxDBk5_8wNZnhOOvWj2HTXocCAso)\n",
      "Tracabililit√© vacances de Toussaint (10WCgjGZ8HVG0fXOxNn-MNCfQj1cBFexy8pyK1GZbqVc)\n",
      "elements of statistical learning (1C1ywy0ud7QBS6T9ZKELcI2tKJqavDR-F)\n",
      "Weatherwax_Epstein_Hastie_Solution_Manual.pdf (1xLcY1lIRhYc70BTcJOwUPFZr1FwZ8kLe)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    # Call the Drive v3 API\n",
    "    results = service\\\n",
    "        .files()\\\n",
    "        .list(\n",
    "            pageSize=10, \n",
    "            fields=\"nextPageToken, files(id, name)\"\n",
    "        ).execute()\n",
    "    \n",
    "    items = results.get('files', [])\n",
    "\n",
    "    if not items:\n",
    "        print('No files found.')\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('Files:')\n",
    "        for item in items:\n",
    "            print(u'{0} ({1})'.format(item['name'], item['id']))\n",
    "except HttpError as error:\n",
    "    # TODO(developer) - Handle errors from drive API.\n",
    "    print(f'An error occurred: {error}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'creds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pedro/Desktop/Polytechnique/few-shot-learning-transformers/notebooks/04-drive_script.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pedro/Desktop/Polytechnique/few-shot-learning-transformers/notebooks/04-drive_script.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pedro/Desktop/Polytechnique/few-shot-learning-transformers/notebooks/04-drive_script.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# create drive api client\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/pedro/Desktop/Polytechnique/few-shot-learning-transformers/notebooks/04-drive_script.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     service \u001b[39m=\u001b[39m build(\u001b[39m'\u001b[39m\u001b[39mdrive\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mv3\u001b[39m\u001b[39m'\u001b[39m, credentials\u001b[39m=\u001b[39mcreds)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pedro/Desktop/Polytechnique/few-shot-learning-transformers/notebooks/04-drive_script.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     file_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1y5hkcTQE5NlioxaPk2Lo9JqExBBMkjQD\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pedro/Desktop/Polytechnique/few-shot-learning-transformers/notebooks/04-drive_script.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# pylint: disable=maybe-no-member\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'creds' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # create drive api client\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    file_id = \"1y5hkcTQE5NlioxaPk2Lo9JqExBBMkjQD\"\n",
    "\n",
    "    # pylint: disable=maybe-no-member\n",
    "    request = service.files().get_media(fileId=file_id)\n",
    "    file = io.BytesIO()\n",
    "    downloader = MediaIoBaseDownload(file, request)\n",
    "    done = False\n",
    "    while done is False:\n",
    "        status, done = downloader.next_chunk()\n",
    "        print(F'Download {int(status.progress() * 100)}.')\n",
    "\n",
    "except HttpError as error:\n",
    "    print(F'An error occurred: {error}')\n",
    "    file = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = file.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 453M/453M [00:03<00:00, 115MB/s]  \n",
      "Some weights of LayoutLMForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = LayoutLMForTokenClassification.from_pretrained(\n",
    "    'microsoft/layoutlm-base-uncased',\n",
    "    num_labels=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"data/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.readlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "# Create GoogleDrive instance with authenticated GoogleAuth instance.\n",
    "drive = GoogleDrive(creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.oauth2.credentials.Credentials at 0x7f258b4761d0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive.auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['layoutlm.embeddings.word_embeddings.weight', 'layoutlm.embeddings.position_embeddings.weight', 'layoutlm.embeddings.x_position_embeddings.weight', 'layoutlm.embeddings.y_position_embeddings.weight', 'layoutlm.embeddings.h_position_embeddings.weight', 'layoutlm.embeddings.w_position_embeddings.weight', 'layoutlm.embeddings.token_type_embeddings.weight', 'layoutlm.embeddings.LayerNorm.weight', 'layoutlm.embeddings.LayerNorm.bias', 'layoutlm.encoder.layer.0.attention.self.query.weight', 'layoutlm.encoder.layer.0.attention.self.query.bias', 'layoutlm.encoder.layer.0.attention.self.key.weight', 'layoutlm.encoder.layer.0.attention.self.key.bias', 'layoutlm.encoder.layer.0.attention.self.value.weight', 'layoutlm.encoder.layer.0.attention.self.value.bias', 'layoutlm.encoder.layer.0.attention.output.dense.weight', 'layoutlm.encoder.layer.0.attention.output.dense.bias', 'layoutlm.encoder.layer.0.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.0.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.0.intermediate.dense.weight', 'layoutlm.encoder.layer.0.intermediate.dense.bias', 'layoutlm.encoder.layer.0.output.dense.weight', 'layoutlm.encoder.layer.0.output.dense.bias', 'layoutlm.encoder.layer.0.output.LayerNorm.weight', 'layoutlm.encoder.layer.0.output.LayerNorm.bias', 'layoutlm.encoder.layer.1.attention.self.query.weight', 'layoutlm.encoder.layer.1.attention.self.query.bias', 'layoutlm.encoder.layer.1.attention.self.key.weight', 'layoutlm.encoder.layer.1.attention.self.key.bias', 'layoutlm.encoder.layer.1.attention.self.value.weight', 'layoutlm.encoder.layer.1.attention.self.value.bias', 'layoutlm.encoder.layer.1.attention.output.dense.weight', 'layoutlm.encoder.layer.1.attention.output.dense.bias', 'layoutlm.encoder.layer.1.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.1.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.1.intermediate.dense.weight', 'layoutlm.encoder.layer.1.intermediate.dense.bias', 'layoutlm.encoder.layer.1.output.dense.weight', 'layoutlm.encoder.layer.1.output.dense.bias', 'layoutlm.encoder.layer.1.output.LayerNorm.weight', 'layoutlm.encoder.layer.1.output.LayerNorm.bias', 'layoutlm.encoder.layer.2.attention.self.query.weight', 'layoutlm.encoder.layer.2.attention.self.query.bias', 'layoutlm.encoder.layer.2.attention.self.key.weight', 'layoutlm.encoder.layer.2.attention.self.key.bias', 'layoutlm.encoder.layer.2.attention.self.value.weight', 'layoutlm.encoder.layer.2.attention.self.value.bias', 'layoutlm.encoder.layer.2.attention.output.dense.weight', 'layoutlm.encoder.layer.2.attention.output.dense.bias', 'layoutlm.encoder.layer.2.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.2.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.2.intermediate.dense.weight', 'layoutlm.encoder.layer.2.intermediate.dense.bias', 'layoutlm.encoder.layer.2.output.dense.weight', 'layoutlm.encoder.layer.2.output.dense.bias', 'layoutlm.encoder.layer.2.output.LayerNorm.weight', 'layoutlm.encoder.layer.2.output.LayerNorm.bias', 'layoutlm.encoder.layer.3.attention.self.query.weight', 'layoutlm.encoder.layer.3.attention.self.query.bias', 'layoutlm.encoder.layer.3.attention.self.key.weight', 'layoutlm.encoder.layer.3.attention.self.key.bias', 'layoutlm.encoder.layer.3.attention.self.value.weight', 'layoutlm.encoder.layer.3.attention.self.value.bias', 'layoutlm.encoder.layer.3.attention.output.dense.weight', 'layoutlm.encoder.layer.3.attention.output.dense.bias', 'layoutlm.encoder.layer.3.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.3.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.3.intermediate.dense.weight', 'layoutlm.encoder.layer.3.intermediate.dense.bias', 'layoutlm.encoder.layer.3.output.dense.weight', 'layoutlm.encoder.layer.3.output.dense.bias', 'layoutlm.encoder.layer.3.output.LayerNorm.weight', 'layoutlm.encoder.layer.3.output.LayerNorm.bias', 'layoutlm.encoder.layer.4.attention.self.query.weight', 'layoutlm.encoder.layer.4.attention.self.query.bias', 'layoutlm.encoder.layer.4.attention.self.key.weight', 'layoutlm.encoder.layer.4.attention.self.key.bias', 'layoutlm.encoder.layer.4.attention.self.value.weight', 'layoutlm.encoder.layer.4.attention.self.value.bias', 'layoutlm.encoder.layer.4.attention.output.dense.weight', 'layoutlm.encoder.layer.4.attention.output.dense.bias', 'layoutlm.encoder.layer.4.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.4.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.4.intermediate.dense.weight', 'layoutlm.encoder.layer.4.intermediate.dense.bias', 'layoutlm.encoder.layer.4.output.dense.weight', 'layoutlm.encoder.layer.4.output.dense.bias', 'layoutlm.encoder.layer.4.output.LayerNorm.weight', 'layoutlm.encoder.layer.4.output.LayerNorm.bias', 'layoutlm.encoder.layer.5.attention.self.query.weight', 'layoutlm.encoder.layer.5.attention.self.query.bias', 'layoutlm.encoder.layer.5.attention.self.key.weight', 'layoutlm.encoder.layer.5.attention.self.key.bias', 'layoutlm.encoder.layer.5.attention.self.value.weight', 'layoutlm.encoder.layer.5.attention.self.value.bias', 'layoutlm.encoder.layer.5.attention.output.dense.weight', 'layoutlm.encoder.layer.5.attention.output.dense.bias', 'layoutlm.encoder.layer.5.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.5.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.5.intermediate.dense.weight', 'layoutlm.encoder.layer.5.intermediate.dense.bias', 'layoutlm.encoder.layer.5.output.dense.weight', 'layoutlm.encoder.layer.5.output.dense.bias', 'layoutlm.encoder.layer.5.output.LayerNorm.weight', 'layoutlm.encoder.layer.5.output.LayerNorm.bias', 'layoutlm.encoder.layer.6.attention.self.query.weight', 'layoutlm.encoder.layer.6.attention.self.query.bias', 'layoutlm.encoder.layer.6.attention.self.key.weight', 'layoutlm.encoder.layer.6.attention.self.key.bias', 'layoutlm.encoder.layer.6.attention.self.value.weight', 'layoutlm.encoder.layer.6.attention.self.value.bias', 'layoutlm.encoder.layer.6.attention.output.dense.weight', 'layoutlm.encoder.layer.6.attention.output.dense.bias', 'layoutlm.encoder.layer.6.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.6.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.6.intermediate.dense.weight', 'layoutlm.encoder.layer.6.intermediate.dense.bias', 'layoutlm.encoder.layer.6.output.dense.weight', 'layoutlm.encoder.layer.6.output.dense.bias', 'layoutlm.encoder.layer.6.output.LayerNorm.weight', 'layoutlm.encoder.layer.6.output.LayerNorm.bias', 'layoutlm.encoder.layer.7.attention.self.query.weight', 'layoutlm.encoder.layer.7.attention.self.query.bias', 'layoutlm.encoder.layer.7.attention.self.key.weight', 'layoutlm.encoder.layer.7.attention.self.key.bias', 'layoutlm.encoder.layer.7.attention.self.value.weight', 'layoutlm.encoder.layer.7.attention.self.value.bias', 'layoutlm.encoder.layer.7.attention.output.dense.weight', 'layoutlm.encoder.layer.7.attention.output.dense.bias', 'layoutlm.encoder.layer.7.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.7.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.7.intermediate.dense.weight', 'layoutlm.encoder.layer.7.intermediate.dense.bias', 'layoutlm.encoder.layer.7.output.dense.weight', 'layoutlm.encoder.layer.7.output.dense.bias', 'layoutlm.encoder.layer.7.output.LayerNorm.weight', 'layoutlm.encoder.layer.7.output.LayerNorm.bias', 'layoutlm.encoder.layer.8.attention.self.query.weight', 'layoutlm.encoder.layer.8.attention.self.query.bias', 'layoutlm.encoder.layer.8.attention.self.key.weight', 'layoutlm.encoder.layer.8.attention.self.key.bias', 'layoutlm.encoder.layer.8.attention.self.value.weight', 'layoutlm.encoder.layer.8.attention.self.value.bias', 'layoutlm.encoder.layer.8.attention.output.dense.weight', 'layoutlm.encoder.layer.8.attention.output.dense.bias', 'layoutlm.encoder.layer.8.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.8.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.8.intermediate.dense.weight', 'layoutlm.encoder.layer.8.intermediate.dense.bias', 'layoutlm.encoder.layer.8.output.dense.weight', 'layoutlm.encoder.layer.8.output.dense.bias', 'layoutlm.encoder.layer.8.output.LayerNorm.weight', 'layoutlm.encoder.layer.8.output.LayerNorm.bias', 'layoutlm.encoder.layer.9.attention.self.query.weight', 'layoutlm.encoder.layer.9.attention.self.query.bias', 'layoutlm.encoder.layer.9.attention.self.key.weight', 'layoutlm.encoder.layer.9.attention.self.key.bias', 'layoutlm.encoder.layer.9.attention.self.value.weight', 'layoutlm.encoder.layer.9.attention.self.value.bias', 'layoutlm.encoder.layer.9.attention.output.dense.weight', 'layoutlm.encoder.layer.9.attention.output.dense.bias', 'layoutlm.encoder.layer.9.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.9.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.9.intermediate.dense.weight', 'layoutlm.encoder.layer.9.intermediate.dense.bias', 'layoutlm.encoder.layer.9.output.dense.weight', 'layoutlm.encoder.layer.9.output.dense.bias', 'layoutlm.encoder.layer.9.output.LayerNorm.weight', 'layoutlm.encoder.layer.9.output.LayerNorm.bias', 'layoutlm.encoder.layer.10.attention.self.query.weight', 'layoutlm.encoder.layer.10.attention.self.query.bias', 'layoutlm.encoder.layer.10.attention.self.key.weight', 'layoutlm.encoder.layer.10.attention.self.key.bias', 'layoutlm.encoder.layer.10.attention.self.value.weight', 'layoutlm.encoder.layer.10.attention.self.value.bias', 'layoutlm.encoder.layer.10.attention.output.dense.weight', 'layoutlm.encoder.layer.10.attention.output.dense.bias', 'layoutlm.encoder.layer.10.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.10.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.10.intermediate.dense.weight', 'layoutlm.encoder.layer.10.intermediate.dense.bias', 'layoutlm.encoder.layer.10.output.dense.weight', 'layoutlm.encoder.layer.10.output.dense.bias', 'layoutlm.encoder.layer.10.output.LayerNorm.weight', 'layoutlm.encoder.layer.10.output.LayerNorm.bias', 'layoutlm.encoder.layer.11.attention.self.query.weight', 'layoutlm.encoder.layer.11.attention.self.query.bias', 'layoutlm.encoder.layer.11.attention.self.key.weight', 'layoutlm.encoder.layer.11.attention.self.key.bias', 'layoutlm.encoder.layer.11.attention.self.value.weight', 'layoutlm.encoder.layer.11.attention.self.value.bias', 'layoutlm.encoder.layer.11.attention.output.dense.weight', 'layoutlm.encoder.layer.11.attention.output.dense.bias', 'layoutlm.encoder.layer.11.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.11.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.11.intermediate.dense.weight', 'layoutlm.encoder.layer.11.intermediate.dense.bias', 'layoutlm.encoder.layer.11.output.dense.weight', 'layoutlm.encoder.layer.11.output.dense.bias', 'layoutlm.encoder.layer.11.output.LayerNorm.weight', 'layoutlm.encoder.layer.11.output.LayerNorm.bias', 'layoutlm.pooler.dense.weight', 'layoutlm.pooler.dense.bias', 'classifier.weight', 'classifier.bias'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
